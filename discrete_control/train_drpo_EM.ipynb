{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartpole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2C Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from a2c import A2CAgent \n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Create Gym environment\n",
    "a2c_env = \"CartPole-v1\"\n",
    "env = gym.make(a2c_env)\n",
    "\n",
    "# Check agent class for initialization parameters and initialize agent\n",
    "if a2c_env == \"CartPole-v1\":\n",
    "    gamma = 0.95\n",
    "    lr = 1e-3\n",
    "\n",
    "agent = A2CAgent(env, gamma, lr)\n",
    "\n",
    "# Define training parameters\n",
    "max_episodes = 500\n",
    "max_steps = 500\n",
    "\n",
    "episode_rewards = []\n",
    "run_time = []\n",
    "start_time = time.time()\n",
    "for episode in range(max_episodes):\n",
    "    trajectory = []\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    for step in range(max_steps):\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        trajectory.append((state, action, reward, next_state, done))\n",
    "        episode_reward += reward  \n",
    "        if done or step == max_steps:\n",
    "            episode_rewards.append(episode_reward)\n",
    "            print(\"Episode \" + str(episode) + \": \" + str(episode_reward))\n",
    "            break\n",
    "        state = next_state\n",
    "    agent.update(trajectory, 0)\n",
    "    elapse = time.time() - start_time\n",
    "    run_time.append(elapse)\n",
    "    \n",
    "a2c_rewards = episode_rewards\n",
    "a2c_runtime = run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = './log_files/a2c/' + a2c_env + '-' + str(time.time()) + '.csv' \n",
    "out = np.column_stack((a2c_runtime, a2c_rewards))\n",
    "with open(name, 'ab') as f:\n",
    "    np.savetxt(f, out, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRPO Agent (KL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: -491.76343876458304\n",
      "Episode 1: -504.00273862777925\n",
      "Episode 2: -497.4807915381953\n",
      "Episode 3: -481.71015216735924\n",
      "Episode 4: -420.9890770395866\n",
      "Episode 5: -419.741918642372\n",
      "Episode 6: -365.5660323583432\n",
      "Episode 7: -305.4510198763947\n",
      "Episode 8: -274.03296315902793\n",
      "Episode 9: -233.3684673583299\n",
      "Episode 10: -237.79265755833174\n",
      "Episode 11: -272.2631288416685\n",
      "Episode 12: -294.52618657083315\n",
      "Episode 13: -293.37382169861274\n",
      "Episode 14: -304.3364966416682\n",
      "Episode 15: -272.76994733403194\n",
      "Episode 16: -242.48407003889247\n",
      "Episode 17: -237.2404553458364\n",
      "Episode 18: -245.59054345278093\n",
      "Episode 19: -316.37072381458546\n",
      "Episode 20: -316.4325354708408\n",
      "Episode 21: -237.4084014687513\n",
      "Episode 22: -260.234595161112\n",
      "Episode 23: -243.09391232985956\n",
      "Episode 24: -317.60685074861345\n",
      "Episode 25: -374.94749762916916\n",
      "Episode 26: -198.6663194631924\n",
      "Episode 27: 59.532303385418835\n",
      "Episode 28: 80.12525553402645\n",
      "Episode 29: -212.23709180069417\n",
      "Episode 30: -385.02585035486715\n",
      "Episode 31: -535.2151469534707\n",
      "Episode 32: -527.8137705631918\n",
      "Episode 33: -401.4031505069471\n",
      "Episode 34: -637.9315119569552\n",
      "Episode 35: -353.43071184652695\n",
      "Episode 36: -54.5095272409681\n",
      "Episode 37: -20.975321902082356\n",
      "Episode 38: 228.82676535624677\n",
      "Episode 39: 256.67127007153186\n",
      "Episode 40: 198.42990537500995\n",
      "Episode 41: 135.523771985421\n",
      "Episode 42: 138.30145412014542\n",
      "Episode 43: 182.37550423403448\n",
      "Episode 44: 180.16768814166946\n",
      "Episode 45: 195.87119351458293\n",
      "Episode 46: 109.64708246735489\n",
      "Episode 47: -68.10990240624307\n",
      "Episode 48: -247.50514472222685\n",
      "Episode 49: -219.1898144458239\n",
      "Episode 50: -117.30389294584086\n",
      "Episode 51: 211.78607328336213\n",
      "Episode 52: 238.30714895837653\n",
      "Episode 53: 239.66647338754436\n",
      "Episode 54: 239.58274618337762\n",
      "Episode 55: 239.5256261514332\n",
      "Episode 56: 239.45672430559986\n",
      "Episode 57: 239.45672430559986\n",
      "Episode 58: 239.45672430559986\n",
      "Episode 59: 239.45672430559986\n",
      "Episode 60: 239.45672430559986\n",
      "Episode 61: 239.45672430559986\n",
      "Episode 62: 239.45672430559986\n",
      "Episode 63: 239.45672430559986\n",
      "Episode 64: 239.45672430559986\n",
      "Episode 65: 239.45672430559986\n",
      "Episode 66: 239.45672430559986\n",
      "Episode 67: 239.45672430559986\n",
      "Episode 68: 239.45672430559986\n",
      "Episode 69: 239.45672430559986\n",
      "Episode 70: 239.45672430559986\n",
      "Episode 71: 239.45672430559986\n",
      "Episode 72: 239.45672430559986\n",
      "Episode 73: 239.45672430559986\n",
      "Episode 74: 239.45672430559986\n",
      "Episode 75: 239.45672430559986\n",
      "Episode 76: 239.45672430559986\n",
      "Episode 77: 239.45672430559986\n",
      "Episode 78: 239.45672430559986\n",
      "Episode 79: 239.45672430559986\n",
      "Episode 80: 239.45672430559986\n",
      "Episode 81: 239.45672430559986\n",
      "Episode 82: 239.45672430559986\n",
      "Episode 83: 239.45672430559986\n",
      "Episode 84: 239.45672430559986\n",
      "Episode 85: 239.45672430559986\n",
      "Episode 86: 239.45672430559986\n",
      "Episode 87: 239.45672430559986\n",
      "Episode 88: 239.45672430559986\n",
      "Episode 89: 239.45672430559986\n",
      "Episode 90: 239.45672430559986\n",
      "Episode 91: 239.45672430559986\n",
      "Episode 92: 239.45672430559986\n",
      "Episode 93: 239.45672430559986\n",
      "Episode 94: 239.45672430559986\n",
      "Episode 95: 239.45672430559986\n",
      "Episode 96: 239.45672430559986\n",
      "Episode 97: 239.45672430559986\n",
      "Episode 98: 239.45672430559986\n",
      "Episode 99: 239.45672430559986\n",
      "Episode 100: 239.45672430559986\n",
      "Episode 101: 239.45672430559986\n",
      "Episode 102: 239.45672430559986\n",
      "Episode 103: 239.45672430559986\n",
      "Episode 104: 239.45672430559986\n",
      "Episode 105: 239.45672430559986\n",
      "Episode 106: 239.45672430559986\n",
      "Episode 107: 239.45672430559986\n",
      "Episode 108: 239.45672430559986\n",
      "Episode 109: 239.45672430559986\n",
      "Episode 110: 239.45672430559986\n",
      "Episode 111: 239.45672430559986\n",
      "Episode 112: 239.45672430559986\n",
      "Episode 113: 239.45672430559986\n",
      "Episode 114: 239.45672430559986\n",
      "Episode 115: 239.45672430559986\n",
      "Episode 116: 239.45672430559986\n",
      "Episode 117: 239.45672430559986\n",
      "Episode 118: 239.45672430559986\n",
      "Episode 119: 239.45672430559986\n",
      "Episode 120: 239.45672430559986\n",
      "Episode 121: 239.45672430559986\n",
      "Episode 122: 239.45672430559986\n",
      "Episode 123: 239.45672430559986\n",
      "Episode 124: 239.45672430559986\n",
      "Episode 125: 239.45672430559986\n",
      "Episode 126: 239.45672430559986\n",
      "Episode 127: 239.45672430559986\n",
      "Episode 128: 239.45672430559986\n",
      "Episode 129: 239.45672430559986\n",
      "Episode 130: 239.45672430559986\n",
      "Episode 131: 239.45672430559986\n",
      "Episode 132: 239.45672430559986\n",
      "Episode 133: 239.45672430559986\n",
      "Episode 134: 239.45672430559986\n",
      "Episode 135: 239.45672430559986\n",
      "Episode 136: 239.45672430559986\n",
      "Episode 137: 239.45672430559986\n",
      "Episode 138: 239.45672430559986\n",
      "Episode 139: 239.45672430559986\n",
      "Episode 140: 239.45672430559986\n",
      "Episode 141: 239.45672430559986\n",
      "Episode 142: 239.45672430559986\n",
      "Episode 143: 239.45672430559986\n",
      "Episode 144: 239.45672430559986\n",
      "Episode 145: 239.45672430559986\n",
      "Episode 146: 239.45672430559986\n",
      "Episode 147: 239.45672430559986\n",
      "Episode 148: 239.45672430559986\n",
      "Episode 149: 239.45672430559986\n",
      "Episode 150: 239.45672430559986\n",
      "Episode 151: 239.45672430559986\n",
      "Episode 152: 239.45672430559986\n",
      "Episode 153: 239.45672430559986\n",
      "Episode 154: 239.45672430559986\n",
      "Episode 155: 239.45672430559986\n",
      "Episode 156: 239.45672430559986\n",
      "Episode 157: 239.45672430559986\n",
      "Episode 158: 239.45672430559986\n",
      "Episode 159: 239.45672430559986\n",
      "Episode 160: 239.45672430559986\n",
      "Episode 161: 239.45672430559986\n",
      "Episode 162: 239.45672430559986\n",
      "Episode 163: 239.45672430559986\n",
      "Episode 164: 239.45672430559986\n",
      "Episode 165: 239.45672430559986\n",
      "Episode 166: 239.45672430559986\n",
      "Episode 167: 239.45672430559986\n",
      "Episode 168: 239.45672430559986\n",
      "Episode 169: 239.45672430559986\n",
      "Episode 170: 239.45672430559986\n",
      "Episode 171: 239.45672430559986\n",
      "Episode 172: 239.45672430559986\n",
      "Episode 173: 239.45672430559986\n",
      "Episode 174: 239.45672430559986\n",
      "Episode 175: 239.45672430559986\n",
      "Episode 176: 239.45672430559986\n",
      "Episode 177: 239.45672430559986\n",
      "Episode 178: 239.45672430559986\n",
      "Episode 179: 239.45672430559986\n",
      "Episode 180: 239.45672430559986\n",
      "Episode 181: 239.45672430559986\n",
      "Episode 182: 239.45672430559986\n",
      "Episode 183: 239.45672430559986\n",
      "Episode 184: 239.45672430559986\n",
      "Episode 185: 239.45672430559986\n",
      "Episode 186: 239.45672430559986\n",
      "Episode 187: 239.45672430559986\n",
      "Episode 188: 239.45672430559986\n",
      "Episode 189: 239.45672430559986\n",
      "Episode 190: 239.45672430559986\n",
      "Episode 191: 239.45672430559986\n",
      "Episode 192: 239.45672430559986\n",
      "Episode 193: 239.45672430559986\n",
      "Episode 194: 239.45672430559986\n",
      "Episode 195: 239.45672430559986\n",
      "Episode 196: 239.45672430559986\n",
      "Episode 197: 239.45672430559986\n",
      "Episode 198: 239.45672430559986\n",
      "Episode 199: 239.45672430559986\n",
      "Episode 200: 239.45672430559986\n",
      "Episode 201: 239.45672430559986\n",
      "Episode 202: 239.45672430559986\n",
      "Episode 203: 239.45672430559986\n",
      "Episode 204: 239.45672430559986\n",
      "Episode 205: 239.45672430559986\n",
      "Episode 206: 239.45672430559986\n",
      "Episode 207: 239.45672430559986\n",
      "Episode 208: 239.45672430559986\n",
      "Episode 209: 239.45672430559986\n",
      "Episode 210: 239.45672430559986\n",
      "Episode 211: 239.45672430559986\n",
      "Episode 212: 239.45672430559986\n",
      "Episode 213: 239.45672430559986\n",
      "Episode 214: 239.45672430559986\n",
      "Episode 215: 239.45672430559986\n",
      "Episode 216: 239.45672430559986\n",
      "Episode 217: 239.45672430559986\n",
      "Episode 218: 239.45672430559986\n",
      "Episode 219: 239.45672430559986\n",
      "Episode 220: 239.45672430559986\n",
      "Episode 221: 239.45672430559986\n",
      "Episode 222: 239.45672430559986\n",
      "Episode 223: 239.45672430559986\n",
      "Episode 224: 239.45672430559986\n",
      "Episode 225: 239.45672430559986\n",
      "Episode 226: 239.45672430559986\n",
      "Episode 227: 239.45672430559986\n",
      "Episode 228: 239.45672430559986\n",
      "Episode 229: 239.45672430559986\n",
      "Episode 230: 239.45672430559986\n",
      "Episode 231: 239.45672430559986\n",
      "Episode 232: 239.45672430559986\n",
      "Episode 233: 239.45672430559986\n",
      "Episode 234: 239.45672430559986\n",
      "Episode 235: 239.45672430559986\n",
      "Episode 236: 239.45672430559986\n",
      "Episode 237: 239.45672430559986\n",
      "Episode 238: 239.45672430559986\n",
      "Episode 239: 239.45672430559986\n",
      "Episode 240: 239.45672430559986\n",
      "Episode 241: 239.45672430559986\n",
      "Episode 242: 239.45672430559986\n",
      "Episode 243: 239.45672430559986\n",
      "Episode 244: 239.45672430559986\n",
      "Episode 245: 239.45672430559986\n",
      "Episode 246: 239.45672430559986\n",
      "Episode 247: 239.45672430559986\n",
      "Episode 248: 239.45672430559986\n",
      "Episode 249: 239.45672430559986\n",
      "Episode 250: 239.45672430559986\n",
      "Episode 251: 239.45672430559986\n",
      "Episode 252: 239.45672430559986\n",
      "Episode 253: 239.45672430559986\n",
      "Episode 254: 239.45672430559986\n",
      "Episode 255: 239.45672430559986\n",
      "Episode 256: 239.45672430559986\n",
      "Episode 257: 239.45672430559986\n",
      "Episode 258: 239.45672430559986\n",
      "Episode 259: 239.45672430559986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 260: 239.45672430559986\n",
      "Episode 261: 239.45672430559986\n",
      "Episode 262: 239.45672430559986\n",
      "Episode 263: 239.45672430559986\n",
      "Episode 264: 239.45672430559986\n",
      "Episode 265: 239.45672430559986\n",
      "Episode 266: 239.45672430559986\n",
      "Episode 267: 239.45672430559986\n",
      "Episode 268: 239.45672430559986\n",
      "Episode 269: 239.45672430559986\n",
      "Episode 270: 239.45672430559986\n",
      "Episode 271: 239.45672430559986\n",
      "Episode 272: 239.45672430559986\n",
      "Episode 273: 239.45672430559986\n",
      "Episode 274: 239.45672430559986\n",
      "Episode 275: 239.45672430559986\n",
      "Episode 276: 239.45672430559986\n",
      "Episode 277: 239.45672430559986\n",
      "Episode 278: 239.45672430559986\n",
      "Episode 279: 239.45672430559986\n",
      "Episode 280: 239.45672430559986\n",
      "Episode 281: 239.45672430559986\n",
      "Episode 282: 239.45672430559986\n",
      "Episode 283: 239.45672430559986\n",
      "Episode 284: 239.45672430559986\n",
      "Episode 285: 239.45672430559986\n",
      "Episode 286: 239.45672430559986\n",
      "Episode 287: 239.45672430559986\n",
      "Episode 288: 239.45672430559986\n",
      "Episode 289: 239.45672430559986\n",
      "Episode 290: 239.45672430559986\n",
      "Episode 291: 239.45672430559986\n",
      "Episode 292: 239.45672430559986\n",
      "Episode 293: 239.45672430559986\n",
      "Episode 294: 239.45672430559986\n",
      "Episode 295: 239.45672430559986\n",
      "Episode 296: 239.45672430559986\n",
      "Episode 297: 239.45672430559986\n",
      "Episode 298: 239.45672430559986\n",
      "Episode 299: 239.45672430559986\n",
      "Episode 300: 239.45672430559986\n",
      "Episode 301: 239.45672430559986\n",
      "Episode 302: 239.45672430559986\n",
      "Episode 303: 239.45672430559986\n",
      "Episode 304: 239.45672430559986\n",
      "Episode 305: 239.45672430559986\n",
      "Episode 306: 239.45672430559986\n",
      "Episode 307: 239.45672430559986\n",
      "Episode 308: 239.45672430559986\n",
      "Episode 309: 239.45672430559986\n",
      "Episode 310: 239.45672430559986\n",
      "Episode 311: 239.45672430559986\n",
      "Episode 312: 239.45672430559986\n",
      "Episode 313: 239.45672430559986\n",
      "Episode 314: 239.45672430559986\n",
      "Episode 315: 239.45672430559986\n",
      "Episode 316: 239.45672430559986\n",
      "Episode 317: 239.45672430559986\n",
      "Episode 318: 239.45672430559986\n",
      "Episode 319: 239.45672430559986\n",
      "Episode 320: 239.45672430559986\n",
      "Episode 321: 239.45672430559986\n",
      "Episode 322: 239.45672430559986\n",
      "Episode 323: 239.45672430559986\n",
      "Episode 324: 239.45672430559986\n",
      "Episode 325: 239.45672430559986\n",
      "Episode 326: 239.45672430559986\n",
      "Episode 327: 239.45672430559986\n",
      "Episode 328: 239.45672430559986\n",
      "Episode 329: 239.45672430559986\n",
      "Episode 330: 239.45672430559986\n",
      "Episode 331: 239.45672430559986\n",
      "Episode 332: 239.45672430559986\n",
      "Episode 333: 239.45672430559986\n",
      "Episode 334: 239.45672430559986\n",
      "Episode 335: 239.45672430559986\n",
      "Episode 336: 239.45672430559986\n",
      "Episode 337: 239.45672430559986\n",
      "Episode 338: 239.45672430559986\n",
      "Episode 339: 239.45672430559986\n",
      "Episode 340: 239.45672430559986\n",
      "Episode 341: 239.45672430559986\n",
      "Episode 342: 239.45672430559986\n",
      "Episode 343: 239.45672430559986\n",
      "Episode 344: 239.45672430559986\n",
      "Episode 345: 239.45672430559986\n",
      "Episode 346: 239.45672430559986\n",
      "Episode 347: 239.45672430559986\n",
      "Episode 348: 239.45672430559986\n",
      "Episode 349: 239.45672430559986\n",
      "Episode 350: 239.45672430559986\n",
      "Episode 351: 239.45672430559986\n",
      "Episode 352: 239.45672430559986\n",
      "Episode 353: 239.45672430559986\n",
      "Episode 354: 239.45672430559986\n",
      "Episode 355: 239.45672430559986\n",
      "Episode 356: 239.45672430559986\n",
      "Episode 357: 239.45672430559986\n",
      "Episode 358: 239.45672430559986\n",
      "Episode 359: 239.45672430559986\n",
      "Episode 360: 239.45672430559986\n",
      "Episode 361: 239.45672430559986\n",
      "Episode 362: 239.45672430559986\n",
      "Episode 363: 239.45672430559986\n",
      "Episode 364: 239.45672430559986\n",
      "Episode 365: 239.45672430559986\n",
      "Episode 366: 239.45672430559986\n",
      "Episode 367: 239.45672430559986\n",
      "Episode 368: 239.45672430559986\n",
      "Episode 369: 239.45672430559986\n",
      "Episode 370: 239.45672430559986\n",
      "Episode 371: 239.45672430559986\n",
      "Episode 372: 239.45672430559986\n",
      "Episode 373: 239.45672430559986\n",
      "Episode 374: 239.45672430559986\n",
      "Episode 375: 239.45672430559986\n",
      "Episode 376: 239.45672430559986\n",
      "Episode 377: 239.45672430559986\n",
      "Episode 378: 239.45672430559986\n",
      "Episode 379: 239.45672430559986\n",
      "Episode 380: 239.45672430559986\n",
      "Episode 381: 239.45672430559986\n",
      "Episode 382: 239.45672430559986\n",
      "Episode 383: 239.45672430559986\n",
      "Episode 384: 239.45672430559986\n",
      "Episode 385: 239.45672430559986\n",
      "Episode 386: 239.45672430559986\n",
      "Episode 387: 239.45672430559986\n",
      "Episode 388: 239.45672430559986\n",
      "Episode 389: 239.45672430559986\n",
      "Episode 390: 239.45672430559986\n",
      "Episode 391: 239.45672430559986\n",
      "Episode 392: 239.45672430559986\n",
      "Episode 393: 239.45672430559986\n",
      "Episode 394: 239.45672430559986\n",
      "Episode 395: 239.45672430559986\n",
      "Episode 396: 239.45672430559986\n",
      "Episode 397: 239.45672430559986\n",
      "Episode 398: 239.45672430559986\n",
      "Episode 399: 239.45672430559986\n",
      "Episode 400: 239.45672430559986\n",
      "Episode 401: 239.45672430559986\n",
      "Episode 402: 239.45672430559986\n",
      "Episode 403: 239.45672430559986\n",
      "Episode 404: 239.45672430559986\n",
      "Episode 405: 239.45672430559986\n",
      "Episode 406: 239.45672430559986\n",
      "Episode 407: 239.45672430559986\n",
      "Episode 408: 239.45672430559986\n",
      "Episode 409: 239.45672430559986\n",
      "Episode 410: 239.45672430559986\n",
      "Episode 411: 239.45672430559986\n",
      "Episode 412: 239.45672430559986\n",
      "Episode 413: 239.45672430559986\n",
      "Episode 414: 239.45672430559986\n",
      "Episode 415: 239.45672430559986\n",
      "Episode 416: 239.45672430559986\n",
      "Episode 417: 239.45672430559986\n",
      "Episode 418: 239.45672430559986\n",
      "Episode 419: 239.45672430559986\n",
      "Episode 420: 239.45672430559986\n",
      "Episode 421: 239.45672430559986\n",
      "Episode 422: 239.45672430559986\n",
      "Episode 423: 239.45672430559986\n",
      "Episode 424: 239.45672430559986\n",
      "Episode 425: 239.45672430559986\n",
      "Episode 426: 239.45672430559986\n",
      "Episode 427: 239.45672430559986\n",
      "Episode 428: 239.45672430559986\n",
      "Episode 429: 239.45672430559986\n",
      "Episode 430: 239.45672430559986\n",
      "Episode 431: 239.45672430559986\n",
      "Episode 432: 239.45672430559986\n",
      "Episode 433: 239.45672430559986\n",
      "Episode 434: 239.45672430559986\n",
      "Episode 435: 239.45672430559986\n",
      "Episode 436: 239.45672430559986\n",
      "Episode 437: 239.45672430559986\n",
      "Episode 438: 239.45672430559986\n",
      "Episode 439: 239.45672430559986\n",
      "Episode 440: 239.45672430559986\n",
      "Episode 441: 239.45672430559986\n",
      "Episode 442: 239.45672430559986\n",
      "Episode 443: 239.45672430559986\n",
      "Episode 444: 239.45672430559986\n",
      "Episode 445: 239.45672430559986\n",
      "Episode 446: 239.45672430559986\n",
      "Episode 447: 239.45672430559986\n",
      "Episode 448: 239.45672430559986\n",
      "Episode 449: 239.45672430559986\n",
      "Episode 450: 239.45672430559986\n",
      "Episode 451: 239.45672430559986\n",
      "Episode 452: 239.45672430559986\n",
      "Episode 453: 239.45672430559986\n",
      "Episode 454: 239.45672430559986\n",
      "Episode 455: 239.45672430559986\n",
      "Episode 456: 239.45672430559986\n",
      "Episode 457: 239.45672430559986\n",
      "Episode 458: 239.45672430559986\n",
      "Episode 459: 239.45672430559986\n",
      "Episode 460: 239.45672430559986\n",
      "Episode 461: 239.45672430559986\n",
      "Episode 462: 239.45672430559986\n",
      "Episode 463: 239.45672430559986\n",
      "Episode 464: 239.45672430559986\n",
      "Episode 465: 239.45672430559986\n",
      "Episode 466: 239.45672430559986\n",
      "Episode 467: 239.45672430559986\n",
      "Episode 468: 239.45672430559986\n",
      "Episode 469: 239.45672430559986\n",
      "Episode 470: 239.45672430559986\n",
      "Episode 471: 239.45672430559986\n",
      "Episode 472: 239.45672430559986\n",
      "Episode 473: 239.45672430559986\n",
      "Episode 474: 239.45672430559986\n",
      "Episode 475: 239.45672430559986\n",
      "Episode 476: 239.45672430559986\n",
      "Episode 477: 239.45672430559986\n",
      "Episode 478: 239.45672430559986\n",
      "Episode 479: 239.45672430559986\n",
      "Episode 480: 239.45672430559986\n",
      "Episode 481: 239.45672430559986\n",
      "Episode 482: 239.45672430559986\n",
      "Episode 483: 239.45672430559986\n",
      "Episode 484: 239.45672430559986\n",
      "Episode 485: 239.45672430559986\n",
      "Episode 486: 239.45672430559986\n",
      "Episode 487: 239.45672430559986\n",
      "Episode 488: 239.45672430559986\n",
      "Episode 489: 239.45672430559986\n",
      "Episode 490: 239.45672430559986\n",
      "Episode 491: 239.45672430559986\n",
      "Episode 492: 239.45672430559986\n",
      "Episode 493: 239.45672430559986\n",
      "Episode 494: 239.45672430559986\n",
      "Episode 495: 239.45672430559986\n",
      "Episode 496: 239.45672430559986\n",
      "Episode 497: 239.45672430559986\n",
      "Episode 498: 239.45672430559986\n",
      "Episode 499: 239.45672430559986\n",
      "Episode 500: 239.45672430559986\n",
      "Episode 501: 239.45672430559986\n",
      "Episode 502: 239.45672430559986\n",
      "Episode 503: 239.45672430559986\n",
      "Episode 504: 239.45672430559986\n",
      "Episode 505: 239.45672430559986\n",
      "Episode 506: 239.45672430559986\n",
      "Episode 507: 239.45672430559986\n",
      "Episode 508: 239.45672430559986\n",
      "Episode 509: 239.45672430559986\n",
      "Episode 510: 239.45672430559986\n",
      "Episode 511: 239.45672430559986\n",
      "Episode 512: 239.45672430559986\n",
      "Episode 513: 239.45672430559986\n",
      "Episode 514: 239.45672430559986\n",
      "Episode 515: 239.45672430559986\n",
      "Episode 516: 239.45672430559986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 517: 239.45672430559986\n",
      "Episode 518: 239.45672430559986\n",
      "Episode 519: 239.45672430559986\n",
      "Episode 520: 239.45672430559986\n",
      "Episode 521: 239.45672430559986\n",
      "Episode 522: 239.45672430559986\n",
      "Episode 523: 239.45672430559986\n",
      "Episode 524: 239.45672430559986\n",
      "Episode 525: 239.45672430559986\n",
      "Episode 526: 239.45672430559986\n",
      "Episode 527: 239.45672430559986\n",
      "Episode 528: 239.45672430559986\n",
      "Episode 529: 239.45672430559986\n",
      "Episode 530: 239.45672430559986\n",
      "Episode 531: 239.45672430559986\n",
      "Episode 532: 239.45672430559986\n",
      "Episode 533: 239.45672430559986\n",
      "Episode 534: 239.45672430559986\n",
      "Episode 535: 239.45672430559986\n",
      "Episode 536: 239.45672430559986\n",
      "Episode 537: 239.45672430559986\n",
      "Episode 538: 239.45672430559986\n",
      "Episode 539: 239.45672430559986\n",
      "Episode 540: 239.45672430559986\n",
      "Episode 541: 239.45672430559986\n",
      "Episode 542: 239.45672430559986\n",
      "Episode 543: 239.45672430559986\n",
      "Episode 544: 239.45672430559986\n",
      "Episode 545: 239.45672430559986\n",
      "Episode 546: 239.45672430559986\n",
      "Episode 547: 239.45672430559986\n",
      "Episode 548: 239.45672430559986\n",
      "Episode 549: 239.45672430559986\n",
      "Episode 550: 239.45672430559986\n",
      "Episode 551: 239.45672430559986\n",
      "Episode 552: 239.45672430559986\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-46cc19ad31ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mtrajectory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code DR-TRPO/odrpo/discrete_control/drpo.py\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_adv_mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import gym_electricitymarket\n",
    "from drpo import DRTRPOAgent \n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Create Gym environment\n",
    "kl_env = 'ElectricityMarketDiscreteDQN-v0'\n",
    "env = gym.make(kl_env)\n",
    "\n",
    "# Check agent class for initialization parameters and initialize agent\n",
    "\n",
    "# When the learning rate is large, policy neural network can overflow and lead to NaNs. \n",
    "# A possible fix is to reduce lr or increase beta to lower the learning rate.\n",
    "\n",
    "if kl_env == \"ElectricityMarketDiscreteDQN-v0\":\n",
    "    gamma = 0.95\n",
    "    lr = 5e-2\n",
    "    beta = 8\n",
    "    \n",
    "agent = DRTRPOAgent(env, gamma, lr)\n",
    "\n",
    "# Define training parameters\n",
    "max_episodes = 1500\n",
    "max_steps = 30\n",
    "\n",
    "episode_rewards = []\n",
    "run_time = []\n",
    "start_time = time.time()\n",
    "for episode in range(max_episodes):\n",
    "    if episode == 0:\n",
    "        first_state = env.reset()\n",
    "    else:\n",
    "        first_state = state\n",
    "    state_adv = []\n",
    "    total_value_loss = 0\n",
    "    \n",
    "    episode_reward = 0\n",
    "    # loop through the first action\n",
    "    for i in range(env.action_space.n):\n",
    "        env.reset()\n",
    "        state = first_state\n",
    "        action = i\n",
    "        trajectory = []\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            if step != 0:\n",
    "                action = agent.get_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            trajectory.append((state, action, reward, next_state, done))\n",
    "            episode_reward += reward  \n",
    "            if done or step == max_steps-1:\n",
    "                break\n",
    "            state = next_state\n",
    "            \n",
    "        adv, value_loss = agent.compute_adv_mc(trajectory)\n",
    "        state_adv.append(adv[0])\n",
    "        total_value_loss += value_loss\n",
    "        \n",
    "    avg_episode_reward = episode_reward/env.action_space.n        \n",
    "    # add randomness for better exploration\n",
    "#     if (avg_episode_reward <= 300) and (episode % 10 == 0):\n",
    "#         state_adv[0] += (np.random.random()-0.5)*0.5\n",
    "#         state_adv[1] += (np.random.random()-0.5)*0.5\n",
    "    \n",
    "#     state_adv[0] += 0.5\n",
    "    \n",
    "    # restart the agent if stuck\n",
    "#     if (episode >= 5) and (avg_episode_reward <= 15):\n",
    "#         agent = DRTRPOAgent(env, gamma, lr)   \n",
    "    \n",
    "    policy_loss = agent.compute_policy_loss_kl(first_state, state_adv, beta)\n",
    "    agent.update(value_loss, policy_loss)\n",
    "    elapse = time.time() - start_time\n",
    "    run_time.append(elapse)\n",
    "    \n",
    "    episode_rewards.append(avg_episode_reward)\n",
    "    print(\"Episode \" + str(episode) + \": \" + str(avg_episode_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_trpo_kl_rewards = episode_rewards\n",
    "dr_trpo_kl_runtime = run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = './log_files/dr_trpo_kl/' + kl_env + '-' + str(time.time()) + '.csv' \n",
    "out = np.column_stack((dr_trpo_kl_runtime, dr_trpo_kl_rewards))\n",
    "with open(name, 'ab') as f:\n",
    "    np.savetxt(f, out, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRPO Agent (Wasserstein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: 20.0\n",
      "Episode 1: 15.0\n",
      "Episode 2: 13.5\n",
      "Episode 3: 12.5\n",
      "Episode 4: 11.0\n",
      "Episode 5: 11.0\n",
      "Episode 6: 15.5\n",
      "Episode 7: 20.0\n",
      "Episode 8: 20.5\n",
      "Episode 9: 20.5\n",
      "Episode 10: 40.0\n",
      "Episode 11: 50.5\n",
      "Episode 12: 86.5\n",
      "Episode 13: 75.0\n",
      "Episode 14: 62.5\n",
      "Episode 15: 56.5\n",
      "Episode 16: 46.5\n",
      "Episode 17: 75.0\n",
      "Episode 18: 46.0\n",
      "Episode 19: 52.5\n",
      "Episode 20: 50.0\n",
      "Episode 21: 35.0\n",
      "Episode 22: 26.0\n",
      "Episode 23: 27.0\n",
      "Episode 24: 17.5\n",
      "Episode 25: 16.5\n",
      "Episode 26: 14.5\n",
      "Episode 27: 20.5\n",
      "Episode 28: 18.0\n",
      "Episode 29: 18.0\n",
      "Episode 30: 19.0\n",
      "Episode 31: 24.0\n",
      "Episode 32: 19.0\n",
      "Episode 33: 27.0\n",
      "Episode 34: 32.0\n",
      "Episode 35: 59.5\n",
      "Episode 36: 71.5\n",
      "Episode 37: 63.0\n",
      "Episode 38: 105.0\n",
      "Episode 39: 41.0\n",
      "Episode 40: 33.5\n",
      "Episode 41: 30.0\n",
      "Episode 42: 26.5\n",
      "Episode 43: 26.5\n",
      "Episode 44: 19.0\n",
      "Episode 45: 28.0\n",
      "Episode 46: 27.0\n",
      "Episode 47: 31.5\n",
      "Episode 48: 38.0\n",
      "Episode 49: 44.0\n",
      "Episode 50: 47.0\n",
      "Episode 51: 83.5\n",
      "Episode 52: 142.5\n",
      "Episode 53: 95.0\n",
      "Episode 54: 76.5\n",
      "Episode 55: 93.5\n",
      "Episode 56: 53.0\n",
      "Episode 57: 91.5\n",
      "Episode 58: 74.5\n",
      "Episode 59: 57.5\n",
      "Episode 60: 49.5\n",
      "Episode 61: 50.5\n",
      "Episode 62: 44.0\n",
      "Episode 63: 56.0\n",
      "Episode 64: 46.0\n",
      "Episode 65: 41.5\n",
      "Episode 66: 49.0\n",
      "Episode 67: 45.0\n",
      "Episode 68: 45.0\n",
      "Episode 69: 48.5\n",
      "Episode 70: 40.5\n",
      "Episode 71: 48.5\n",
      "Episode 72: 43.0\n",
      "Episode 73: 68.0\n",
      "Episode 74: 75.0\n",
      "Episode 75: 99.5\n",
      "Episode 76: 121.5\n",
      "Episode 77: 149.0\n",
      "Episode 78: 135.5\n",
      "Episode 79: 164.5\n",
      "Episode 80: 187.5\n",
      "Episode 81: 246.0\n",
      "Episode 82: 179.5\n",
      "Episode 83: 299.5\n",
      "Episode 84: 273.0\n",
      "Episode 85: 245.5\n",
      "Episode 86: 195.0\n",
      "Episode 87: 239.0\n",
      "Episode 88: 183.5\n",
      "Episode 89: 221.0\n",
      "Episode 90: 250.5\n",
      "Episode 91: 183.5\n",
      "Episode 92: 198.0\n",
      "Episode 93: 194.5\n",
      "Episode 94: 187.5\n",
      "Episode 95: 200.5\n",
      "Episode 96: 194.0\n",
      "Episode 97: 183.0\n",
      "Episode 98: 171.0\n",
      "Episode 99: 182.0\n",
      "Episode 100: 176.0\n",
      "Episode 101: 155.0\n",
      "Episode 102: 177.5\n",
      "Episode 103: 191.5\n",
      "Episode 104: 183.0\n",
      "Episode 105: 179.0\n",
      "Episode 106: 170.0\n",
      "Episode 107: 180.0\n",
      "Episode 108: 176.0\n",
      "Episode 109: 183.0\n",
      "Episode 110: 179.5\n",
      "Episode 111: 180.5\n",
      "Episode 112: 176.5\n",
      "Episode 113: 164.0\n",
      "Episode 114: 169.0\n",
      "Episode 115: 175.0\n",
      "Episode 116: 184.5\n",
      "Episode 117: 188.5\n",
      "Episode 118: 166.0\n",
      "Episode 119: 160.5\n",
      "Episode 120: 172.5\n",
      "Episode 121: 171.5\n",
      "Episode 122: 190.5\n",
      "Episode 123: 164.5\n",
      "Episode 124: 193.0\n",
      "Episode 125: 180.0\n",
      "Episode 126: 173.0\n",
      "Episode 127: 154.5\n",
      "Episode 128: 162.0\n",
      "Episode 129: 187.5\n",
      "Episode 130: 171.5\n",
      "Episode 131: 178.0\n",
      "Episode 132: 180.0\n",
      "Episode 133: 191.5\n",
      "Episode 134: 157.5\n",
      "Episode 135: 154.5\n",
      "Episode 136: 185.0\n",
      "Episode 137: 183.0\n",
      "Episode 138: 186.5\n",
      "Episode 139: 150.5\n",
      "Episode 140: 158.0\n",
      "Episode 141: 175.0\n",
      "Episode 142: 182.5\n",
      "Episode 143: 184.5\n",
      "Episode 144: 188.5\n",
      "Episode 145: 165.5\n",
      "Episode 146: 170.0\n",
      "Episode 147: 168.0\n",
      "Episode 148: 181.0\n",
      "Episode 149: 182.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from drpo import DRTRPOAgent \n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "wass_env = \"CartPole-v1\"\n",
    "# Create Gym environment\n",
    "env = gym.make(wass_env)\n",
    "\n",
    "# Check agent class for initialization parameters and initialize agent\n",
    "if wass_env == \"CartPole-v1\":\n",
    "    gamma = 0.95\n",
    "    lr = 1e-2\n",
    "    \n",
    "agent = DRTRPOAgent(env, gamma, lr)\n",
    "\n",
    "# Define training parameters\n",
    "max_episodes = 150\n",
    "max_steps = 500\n",
    "total_adv_diff = 0\n",
    "\n",
    "episode_rewards = []\n",
    "run_time = []\n",
    "start_time = time.time()\n",
    "for episode in range(max_episodes):\n",
    "    if episode == 0:\n",
    "        first_state = env.reset()\n",
    "    else:\n",
    "        first_state = state\n",
    "    state_adv = []\n",
    "    total_value_loss = 0\n",
    "    \n",
    "    episode_reward = 0\n",
    "    # loop through the first action\n",
    "    for i in range(env.action_space.n):\n",
    "        env.reset()\n",
    "        state = first_state\n",
    "        action = i\n",
    "        trajectory = []\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            if step != 0:\n",
    "                action = agent.get_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            trajectory.append((state, action, reward, next_state, done))\n",
    "            episode_reward += reward  \n",
    "            if done or step == max_steps-1:\n",
    "                break\n",
    "            state = next_state\n",
    "            \n",
    "        adv, value_loss = agent.compute_adv_mc(trajectory)\n",
    "        state_adv.append(adv[0])\n",
    "        total_value_loss += value_loss\n",
    "    \n",
    "    total_adv_diff += abs(state_adv[1] - state_adv[0])\n",
    "    # larger beta, better stability; smaller beta, better exploration\n",
    "    beta = total_adv_diff/episode \n",
    "    beta += np.random.random()*0.3-0.1\n",
    "    \n",
    "    avg_episode_reward = episode_reward/env.action_space.n\n",
    "    # add randomness for better exploration\n",
    "    if (episode % 10 == 0) and (avg_episode_reward <= 350): \n",
    "        state_adv[0] += (np.random.random()-0.5)*0.5\n",
    "        state_adv[1] += (np.random.random()-0.5)*0.5\n",
    "        \n",
    "    state_adv[0] += 0.5\n",
    "        \n",
    "    # restart the agent if stuck\n",
    "    if (episode >= 5) and (avg_episode_reward <= 15):\n",
    "        agent = DRTRPOAgent(env, gamma, lr)\n",
    "    \n",
    "    policy_loss = agent.compute_policy_loss_wass(first_state, state_adv, beta)\n",
    "    agent.update(value_loss, policy_loss)\n",
    "    elapse = time.time() - start_time\n",
    "    run_time.append(elapse)\n",
    "    \n",
    "    episode_rewards.append(avg_episode_reward)\n",
    "    print(\"Episode \" + str(episode) + \": \" + str(avg_episode_reward))\n",
    "\n",
    "dr_trpo_wass_rewards = episode_rewards\n",
    "dr_trpo_wass_runtime = run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = './log_files/dr_trpo_wass/' + wass_env + '-' + str(time.time()) + '.csv' \n",
    "out = np.column_stack((dr_trpo_wass_runtime, dr_trpo_wass_rewards))\n",
    "with open(name, 'ab') as f:\n",
    "    np.savetxt(f, out, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRPO Agent (Sinkhorn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from drpo import DRTRPOAgent \n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "sink_env = \"CartPole-v1\"\n",
    "# Create Gym environment\n",
    "env = gym.make(sink_env)\n",
    "\n",
    "# Check agent class for initialization parameters and initialize agent\n",
    "if wass_env == \"CartPole-v1\":\n",
    "    gamma = 0.95\n",
    "    lr = 1e-2\n",
    "    \n",
    "agent = DRTRPOAgent(env, gamma, lr)\n",
    "\n",
    "# Define training parameters\n",
    "max_episodes = 200\n",
    "max_steps = 500\n",
    "total_adv_diff = 0\n",
    "\n",
    "episode_rewards = []\n",
    "run_time = []\n",
    "start_time = time.time()\n",
    "for episode in range(max_episodes):\n",
    "    if episode == 0:\n",
    "        first_state = env.reset()\n",
    "    else:\n",
    "        first_state = state\n",
    "    state_adv = []\n",
    "    total_value_loss = 0\n",
    "    \n",
    "    episode_reward = 0\n",
    "    # loop through the first action\n",
    "    for i in range(env.action_space.n):\n",
    "        env.reset()\n",
    "        state = first_state\n",
    "        action = i\n",
    "        trajectory = []\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            if step != 0:\n",
    "                action = agent.get_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            trajectory.append((state, action, reward, next_state, done))\n",
    "            episode_reward += reward  \n",
    "            if done or step == max_steps-1:\n",
    "                break\n",
    "            state = next_state\n",
    "            \n",
    "        adv, value_loss = agent.compute_adv_mc(trajectory)\n",
    "        state_adv.append(adv[0])\n",
    "        total_value_loss += value_loss\n",
    "\n",
    "    total_adv_diff += abs(state_adv[1] - state_adv[0])\n",
    "    # larger beta, better stability; smaller beta, better exploration\n",
    "    beta = total_adv_diff/episode \n",
    "    beta += np.random.random()*0.3-0.1\n",
    "    \n",
    "    avg_episode_reward = episode_reward/env.action_space.n\n",
    "    # add randomness for better exploration\n",
    "    if (episode % 10 == 0) and (avg_episode_reward <= 350): \n",
    "        state_adv[0] += (np.random.random()-0.5)*0.5\n",
    "        state_adv[1] += (np.random.random()-0.5)*0.5\n",
    "        \n",
    "    # restart the agent if stuck\n",
    "    if (episode >= 5) and (avg_episode_reward <= 10):\n",
    "        agent = DRTRPOAgent(env, gamma, lr)\n",
    "    \n",
    "    beta = 50\n",
    "    policy_loss = agent.compute_policy_loss_sinkhorn(first_state, state_adv, beta)\n",
    "    agent.update(value_loss, policy_loss)\n",
    "    elapse = time.time() - start_time\n",
    "    run_time.append(elapse)\n",
    "    \n",
    "    episode_rewards.append(avg_episode_reward)\n",
    "    print(\"Episode \" + str(episode) + \": \" + str(avg_episode_reward))\n",
    "\n",
    "dr_trpo_sink_rewards = episode_rewards\n",
    "dr_trpo_sink_runtime = run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = './log_files/dr_trpo_sink/' + sink_env + '-' + str(time.time()) + '.csv' \n",
    "out = np.column_stack((dr_trpo_sink_runtime, dr_trpo_sink_rewards))\n",
    "with open(name, 'ab') as f:\n",
    "    np.savetxt(f, out, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
