{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_gridworld\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# DR TRPO related files\n",
    "from grid_train_helper import *\n",
    "from value import NNValueFunction\n",
    "from utils import Logger\n",
    "from grid_dr_policy import DRPolicyKL, DRPolicyWass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Move to Yellow Room"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO KL (online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 2 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 3 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 4 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 5 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 6 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 7 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 8 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 9 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 10 return 73.0000003 discounted reward -3.6035293\n",
      "Episode 11 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 12 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 13 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 14 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 15 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 16 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 17 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 18 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 19 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 20 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 21 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 22 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 23 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 24 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 25 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 26 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 27 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 28 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 29 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 30 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 31 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 32 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 33 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 34 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 35 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 36 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 37 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 38 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 39 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 40 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 41 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 42 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 43 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 44 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 45 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 46 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 47 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 48 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 49 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 50 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 51 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 52 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 53 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 54 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 55 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 56 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 57 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 58 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 59 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 60 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 61 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 62 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 63 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 64 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 65 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 66 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 67 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 68 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 69 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 70 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 71 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 72 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 73 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 74 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 75 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 76 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 77 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 78 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 79 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 80 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 81 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 82 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 83 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 84 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 85 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 86 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 87 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 88 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 89 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 90 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 91 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 92 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 93 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 94 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 95 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 96 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 97 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 98 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 99 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 100 return 95.0000003 discounted reward 54.9539003\n"
     ]
    }
   ],
   "source": [
    "env_name = \"GridWorld-v0\"\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/GridWorld-odrpo/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "    \n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyKL(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 100\n",
    "batch_eps = 1\n",
    "max_steps = 50 # max steps per episode\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "all_values = np.zeros(sta_num)\n",
    "learning_rate = 0.2\n",
    "\n",
    "\n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        value_observe = all_values[observe]\n",
    "        value_next_observe = all_values[next_observe]\n",
    "        # update advantage\n",
    "        all_advantages[observe][action] = all_advantages[observe][action]*(1-learning_rate) + (reward + gamma*value_next_observe - value_observe)*learning_rate\n",
    "        # update value\n",
    "        all_values[observe] = all_values[observe]*(1-learning_rate) + (reward + gamma*value_next_observe)*learning_rate\n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO KL (online) + online human interaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 2 return 61.0000003 discounted reward -8.1934483\n",
      "Episode 3 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 4 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 5 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 6 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 7 return 77.0000003 discounted reward -0.2507683\n",
      "Episode 8 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 9 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 10 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 11 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 12 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 13 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 14 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 15 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 16 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 17 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 18 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 19 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 20 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 21 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 22 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 23 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 24 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 25 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 26 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 27 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 28 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 29 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 30 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 31 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 32 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 33 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 34 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 35 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 36 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 37 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 38 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 39 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 40 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 41 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 42 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 43 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 44 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 45 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 46 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 47 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 48 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 49 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 50 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 51 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 52 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 53 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 54 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 55 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 56 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 57 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 58 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 59 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 60 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 61 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 62 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 63 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 64 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 65 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 66 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 67 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 68 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 69 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 70 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 71 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 72 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 73 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 74 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 75 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 76 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 77 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 78 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 79 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 80 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 81 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 82 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 83 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 84 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 85 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 86 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 87 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 88 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 89 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 90 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 91 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 92 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 93 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 94 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 95 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 96 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 97 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 98 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 99 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 100 return 95.0000003 discounted reward 54.9539003\n"
     ]
    }
   ],
   "source": [
    "env_name = \"GridWorld-v0\"\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/GridWorld-odrpo-online-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "\n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyKL(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 100\n",
    "batch_eps = 1\n",
    "max_steps = 50 # max steps per episode\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "all_values = np.zeros(sta_num)\n",
    "learning_rate = 0.2\n",
    "\n",
    "human_recommendation = dict([(0,2),(8,2),(16,2),(24,1),(32,0),(40,0),(48,0),(1,2),(9,2),(17,2),(25,1),(33,0),(41,0),(49,0),\\\n",
    "                            (26,1),(3,2),(11,2),(19,2),(27,1),(35,0),(43,0),(51,0),(4,2),(12,2),(20,2),(28,1),(36,0),(44,0),(52,0),(29,1)])\n",
    "        \n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        value_observe = all_values[observe]\n",
    "        value_next_observe = all_values[next_observe]\n",
    "        # update advantage\n",
    "        all_advantages[observe][action] = all_advantages[observe][action]*(1-learning_rate) + (reward + gamma*value_next_observe - value_observe)*learning_rate\n",
    "        # update value\n",
    "        all_values[observe] = all_values[observe]*(1-learning_rate) + (reward + gamma*value_next_observe)*learning_rate\n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            #--------------- Human in the loop --------------- #\n",
    "            if human_recommendation[observe] != action: \n",
    "                all_advantages[observe][action] -= 1\n",
    "            else:\n",
    "                all_advantages[observe][action] += 1\n",
    "            #------------------------------------------------- #\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO KL (online) + offline human interaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 2 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 3 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 4 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 5 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 6 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 7 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 8 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 9 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 10 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 11 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 12 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 13 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 14 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 15 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 16 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 17 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 18 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 19 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 20 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 21 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 22 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 23 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 24 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 25 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 26 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 27 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 28 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 29 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 30 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 31 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 32 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 33 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 34 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 35 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 36 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 37 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 38 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 39 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 40 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 41 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 42 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 43 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 44 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 45 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 46 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 47 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 48 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 49 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 50 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 51 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 52 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 53 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 54 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 55 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 56 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 57 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 58 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 59 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 60 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 61 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 62 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 63 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 64 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 65 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 66 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 67 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 68 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 69 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 70 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 71 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 72 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 73 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 74 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 75 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 76 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 77 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 78 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 79 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 80 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 81 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 82 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 83 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 84 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 85 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 86 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 87 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 88 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 89 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 90 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 91 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 92 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 93 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 94 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 95 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 96 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 97 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 98 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 99 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 100 return 95.0000003 discounted reward 54.9539003\n"
     ]
    }
   ],
   "source": [
    "env_name = \"GridWorld-v0\"\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/GridWorld-odrpo-offline-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "\n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyKL(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 100\n",
    "batch_eps = 1\n",
    "max_steps = 50 # max steps per episode\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "all_values = np.zeros(sta_num)\n",
    "learning_rate = 0.2\n",
    "\n",
    "\n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        value_observe = all_values[observe]\n",
    "        value_next_observe = all_values[next_observe]\n",
    "        # update advantage\n",
    "        all_advantages[observe][action] = all_advantages[observe][action]*(1-learning_rate) + (reward + gamma*value_next_observe - value_observe)*learning_rate \n",
    "        # update value\n",
    "        all_values[observe] = all_values[observe]*(1-learning_rate) + (reward + gamma*value_next_observe)*learning_rate \n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "        \n",
    "    # human modifies the advantage\n",
    "    # left red room\n",
    "    all_advantages[0][2] += 1\n",
    "    all_advantages[8][2] += 1\n",
    "    all_advantages[16][2] += 1\n",
    "    all_advantages[24][1] += 1\n",
    "    all_advantages[32][0] += 1\n",
    "    all_advantages[40][0] += 1\n",
    "    all_advantages[48][0] += 1\n",
    "        \n",
    "    all_advantages[1][2] += 1\n",
    "    all_advantages[9][2] += 1\n",
    "    all_advantages[17][2] += 1\n",
    "    all_advantages[25][1] += 1\n",
    "    all_advantages[33][0] += 1\n",
    "    all_advantages[41][0] += 1\n",
    "    all_advantages[49][0] += 1\n",
    "        \n",
    "        \n",
    "    # middle path \n",
    "    all_advantages[26][1] += 1\n",
    "        \n",
    "    # middle blue room\n",
    "    all_advantages[3][2] += 1\n",
    "    all_advantages[11][2] += 1\n",
    "    all_advantages[19][2] += 1\n",
    "    all_advantages[27][1] += 1\n",
    "    all_advantages[35][0] += 1\n",
    "    all_advantages[43][0] += 1\n",
    "    all_advantages[51][0] += 1\n",
    "        \n",
    "    all_advantages[4][2] += 1\n",
    "    all_advantages[12][2] += 1\n",
    "    all_advantages[20][2] += 1\n",
    "    all_advantages[28][1] += 1\n",
    "    all_advantages[36][0] += 1\n",
    "    all_advantages[44][0] += 1\n",
    "    all_advantages[52][0] += 1\n",
    "        \n",
    "    # middle path \n",
    "    all_advantages[29][1] += 1\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO (online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return 1174.0000003 discounted reward 14.0651403\n",
      "Episode 2 return 1390.0000003 discounted reward 14.2740993\n",
      "Episode 3 return 1276.0000003 discounted reward 11.6945903\n",
      "Episode 4 return 1346.0000003 discounted reward 13.7001683\n",
      "Episode 5 return 1282.0000003 discounted reward 9.5815123\n",
      "Episode 6 return 1852.0000003 discounted reward 15.9635843\n",
      "Episode 7 return 1788.0000003 discounted reward 16.7413803\n",
      "Episode 8 return 1848.0000003 discounted reward 15.1362373\n",
      "Episode 9 return 1666.0000003 discounted reward 23.4010663\n",
      "Episode 10 return 1832.0000003 discounted reward 14.1694293\n",
      "Episode 11 return 2026.0000003 discounted reward 18.0635833\n",
      "Episode 12 return 1936.0000003 discounted reward 15.1619543\n",
      "Episode 13 return 2012.0000003 discounted reward 18.9144883\n",
      "Episode 14 return 2176.0000003 discounted reward 18.5112483\n",
      "Episode 15 return 1772.0000003 discounted reward 17.4293403\n",
      "Episode 16 return 2108.0000003 discounted reward 17.4750583\n",
      "Episode 17 return 1926.0000003 discounted reward 22.1862773\n",
      "Episode 18 return 2224.0000003 discounted reward 20.4103293\n",
      "Episode 19 return 2212.0000003 discounted reward 17.2377963\n",
      "Episode 20 return 2120.0000003 discounted reward 15.4266513\n",
      "Episode 21 return 2204.0000003 discounted reward 18.2585333\n",
      "Episode 22 return 2410.0000003 discounted reward 19.0467513\n",
      "Episode 23 return 2296.0000003 discounted reward 15.9176743\n",
      "Episode 24 return 2308.0000003 discounted reward 20.1854143\n",
      "Episode 25 return 2488.0000003 discounted reward 19.5714443\n",
      "Episode 26 return 2176.0000003 discounted reward 16.2402873\n",
      "Episode 27 return 2222.0000003 discounted reward 17.1834713\n",
      "Episode 28 return 2742.0000003 discounted reward 24.7158633\n",
      "Episode 29 return 3118.0000003 discounted reward 23.4536003\n",
      "Episode 30 return 3126.0000003 discounted reward 17.8748323\n",
      "Episode 31 return 3318.0000003 discounted reward 16.5888793\n",
      "Episode 32 return 3064.0000003 discounted reward 20.6615333\n",
      "Episode 33 return 2860.0000003 discounted reward 18.3089623\n",
      "Episode 34 return 2962.0000003 discounted reward 19.0864013\n",
      "Episode 35 return 2874.0000003 discounted reward 16.0786303\n",
      "Episode 36 return 2636.0000003 discounted reward 19.9920053\n",
      "Episode 37 return 2974.0000003 discounted reward 10.2747063\n",
      "Episode 38 return 2748.0000003 discounted reward 15.8552483\n",
      "Episode 39 return 3080.0000003 discounted reward 16.4029473\n",
      "Episode 40 return 3796.0000003 discounted reward 23.6150363\n",
      "Episode 41 return 3186.0000003 discounted reward 45.5420413\n",
      "Episode 42 return 2960.0000003 discounted reward 15.0685183\n",
      "Episode 43 return 2756.0000003 discounted reward 15.3848993\n",
      "Episode 44 return 2942.0000003 discounted reward 21.6410933\n",
      "Episode 45 return 3256.0000003 discounted reward 23.4455373\n",
      "Episode 46 return 2832.0000003 discounted reward 19.1758703\n",
      "Episode 47 return 3678.0000003 discounted reward 16.8890883\n",
      "Episode 48 return 2994.0000003 discounted reward 17.1260063\n",
      "Episode 49 return 2514.0000003 discounted reward 15.7572723\n",
      "Episode 50 return 3082.0000003 discounted reward 28.7290273\n",
      "Episode 51 return 3050.0000003 discounted reward 10.8783473\n",
      "Episode 52 return 3182.0000003 discounted reward 18.9318183\n",
      "Episode 53 return 2476.0000003 discounted reward 19.3460643\n",
      "Episode 54 return 3002.0000003 discounted reward 19.3468583\n",
      "Episode 55 return 2548.0000003 discounted reward 22.1488353\n",
      "Episode 56 return 2740.0000003 discounted reward 16.2204353\n",
      "Episode 57 return 3482.0000003 discounted reward 33.1247743\n",
      "Episode 58 return 3584.0000003 discounted reward 16.9170543\n",
      "Episode 59 return 2884.0000003 discounted reward 32.6009683\n",
      "Episode 60 return 3358.0000003 discounted reward 31.0988433\n",
      "Episode 61 return 2920.0000003 discounted reward 21.7500643\n",
      "Episode 62 return 2926.0000003 discounted reward 14.2654743\n",
      "Episode 63 return 3018.0000003 discounted reward 16.0647423\n",
      "Episode 64 return 2788.0000003 discounted reward 18.4156323\n",
      "Episode 65 return 3168.0000003 discounted reward 16.4684743\n",
      "Episode 66 return 3554.0000003 discounted reward 11.8935493\n",
      "Episode 67 return 2898.0000003 discounted reward 44.8539463\n",
      "Episode 68 return 2658.0000003 discounted reward 32.0744303\n",
      "Episode 69 return 3294.0000003 discounted reward 26.6462973\n",
      "Episode 70 return 3216.0000003 discounted reward 44.3701793\n",
      "Episode 71 return 3308.0000003 discounted reward 16.3821593\n",
      "Episode 72 return 3116.0000003 discounted reward 14.4475203\n",
      "Episode 73 return 2888.0000003 discounted reward 14.0053243\n",
      "Episode 74 return 2824.0000003 discounted reward 23.9898233\n",
      "Episode 75 return 3100.0000003 discounted reward 21.9182403\n",
      "Episode 76 return 2952.0000003 discounted reward 19.9743603\n",
      "Episode 77 return 3170.0000003 discounted reward 20.6747663\n",
      "Episode 78 return 3410.0000003 discounted reward 23.2709423\n",
      "Episode 79 return 3200.0000003 discounted reward 37.5938323\n",
      "Episode 80 return 3106.0000003 discounted reward 22.3632203\n",
      "Episode 81 return 3138.0000003 discounted reward 23.7757003\n",
      "Episode 82 return 2868.0000003 discounted reward 30.5415043\n",
      "Episode 83 return 3294.0000003 discounted reward 10.2852653\n",
      "Episode 84 return 3062.0000003 discounted reward 14.1536253\n",
      "Episode 85 return 3270.0000003 discounted reward 17.9998923\n",
      "Episode 86 return 3072.0000003 discounted reward 27.8143503\n",
      "Episode 87 return 2940.0000003 discounted reward 33.2340123\n",
      "Episode 88 return 2706.0000003 discounted reward 39.5342493\n",
      "Episode 89 return 2926.0000003 discounted reward 17.6519793\n",
      "Episode 90 return 2892.0000003 discounted reward 17.9791313\n",
      "Episode 91 return 3062.0000003 discounted reward 20.7236343\n",
      "Episode 92 return 2772.0000003 discounted reward 14.5697543\n",
      "Episode 93 return 3132.0000003 discounted reward 16.6560933\n",
      "Episode 94 return 3544.0000003 discounted reward 41.2152973\n",
      "Episode 95 return 3188.0000003 discounted reward 36.6144863\n",
      "Episode 96 return 2918.0000003 discounted reward 19.4675573\n",
      "Episode 97 return 2724.0000003 discounted reward 21.8219933\n",
      "Episode 98 return 3148.0000003 discounted reward 21.8314453\n",
      "Episode 99 return 3098.0000003 discounted reward 25.1340253\n",
      "Episode 100 return 3300.0000003 discounted reward 18.0154703\n",
      "Episode 101 return 2820.0000003 discounted reward 20.5831673\n",
      "Episode 102 return 3532.0000003 discounted reward 22.6377113\n",
      "Episode 103 return 3234.0000003 discounted reward 48.8776153\n",
      "Episode 104 return 3034.0000003 discounted reward 29.3800393\n",
      "Episode 105 return 2984.0000003 discounted reward 34.8171483\n",
      "Episode 106 return 2666.0000003 discounted reward 19.8134133\n",
      "Episode 107 return 3448.0000003 discounted reward 16.3096263\n",
      "Episode 108 return 2574.0000003 discounted reward 21.9809323\n",
      "Episode 109 return 3254.0000003 discounted reward 12.9017463\n",
      "Episode 110 return 3778.0000003 discounted reward 13.9732933\n",
      "Episode 111 return 2696.0000003 discounted reward 20.1835483\n",
      "Episode 112 return 3474.0000003 discounted reward 13.5633633\n",
      "Episode 113 return 3096.0000003 discounted reward 18.6971623\n",
      "Episode 114 return 2794.0000003 discounted reward 16.1201633\n",
      "Episode 115 return 3230.0000003 discounted reward 36.5943403\n",
      "Episode 116 return 2272.0000003 discounted reward 18.4284093\n",
      "Episode 117 return 2960.0000003 discounted reward 20.9905753\n",
      "Episode 118 return 3076.0000003 discounted reward 30.0612353\n",
      "Episode 119 return 2724.0000003 discounted reward 18.9056243\n",
      "Episode 120 return 2976.0000003 discounted reward 15.3942773\n",
      "Episode 121 return 3316.0000003 discounted reward 21.2760133\n",
      "Episode 122 return 2944.0000003 discounted reward 24.0182483\n",
      "Episode 123 return 3116.0000003 discounted reward 35.0120493\n",
      "Episode 124 return 2616.0000003 discounted reward 20.0695753\n",
      "Episode 125 return 2492.0000003 discounted reward 18.6392993\n",
      "Episode 126 return 2632.0000003 discounted reward 20.9186513\n",
      "Episode 127 return 2920.0000003 discounted reward 16.4746713\n",
      "Episode 128 return 3084.0000003 discounted reward 22.9395573\n",
      "Episode 129 return 3010.0000003 discounted reward 14.2965963\n",
      "Episode 130 return 3212.0000003 discounted reward 13.9871503\n",
      "Episode 131 return 2888.0000003 discounted reward 23.4640953\n",
      "Episode 132 return 3272.0000003 discounted reward 17.1491123\n",
      "Episode 133 return 2884.0000003 discounted reward 17.1719303\n",
      "Episode 134 return 2764.0000003 discounted reward 25.1347953\n",
      "Episode 135 return 3048.0000003 discounted reward 19.0363923\n",
      "Episode 136 return 2912.0000003 discounted reward 22.4339523\n",
      "Episode 137 return 2714.0000003 discounted reward 21.4550653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 138 return 3078.0000003 discounted reward 30.6741623\n",
      "Episode 139 return 3348.0000003 discounted reward 17.4507633\n",
      "Episode 140 return 2898.0000003 discounted reward 47.3585933\n",
      "Episode 141 return 3200.0000003 discounted reward 20.1274293\n",
      "Episode 142 return 3200.0000003 discounted reward 18.8372133\n",
      "Episode 143 return 3104.0000003 discounted reward 19.4762333\n",
      "Episode 144 return 2918.0000003 discounted reward 32.5015163\n",
      "Episode 145 return 2652.0000003 discounted reward 28.1397443\n",
      "Episode 146 return 3106.0000003 discounted reward 15.8942373\n",
      "Episode 147 return 2904.0000003 discounted reward 21.1143033\n",
      "Episode 148 return 3150.0000003 discounted reward 17.3923473\n",
      "Episode 149 return 3194.0000003 discounted reward 27.0967593\n",
      "Episode 150 return 3218.0000003 discounted reward 17.7627973\n",
      "Episode 151 return 2894.0000003 discounted reward 19.0300373\n",
      "Episode 152 return 2856.0000003 discounted reward 15.3206193\n",
      "Episode 153 return 3244.0000003 discounted reward 38.3822963\n",
      "Episode 154 return 2942.0000003 discounted reward 34.7396403\n",
      "Episode 155 return 2858.0000003 discounted reward 25.6267353\n",
      "Episode 156 return 3184.0000003 discounted reward 17.6927083\n",
      "Episode 157 return 2768.0000003 discounted reward 20.2378573\n",
      "Episode 158 return 3068.0000003 discounted reward 24.3921623\n",
      "Episode 159 return 3254.0000003 discounted reward 16.0220743\n",
      "Episode 160 return 2700.0000003 discounted reward 23.5672173\n",
      "Episode 161 return 3080.0000003 discounted reward 22.6879543\n",
      "Episode 162 return 3368.0000003 discounted reward 22.1252933\n",
      "Episode 163 return 2938.0000003 discounted reward 25.1144343\n",
      "Episode 164 return 2870.0000003 discounted reward 15.2878673\n",
      "Episode 165 return 3024.0000003 discounted reward 22.0249253\n",
      "Episode 166 return 2970.0000003 discounted reward 7.7700003\n",
      "Episode 167 return 3492.0000003 discounted reward 29.6334613\n",
      "Episode 168 return 3684.0000003 discounted reward 14.5268663\n",
      "Episode 169 return 2830.0000003 discounted reward 29.7378003\n",
      "Episode 170 return 2600.0000003 discounted reward 22.5034063\n",
      "Episode 171 return 3172.0000003 discounted reward 22.7782513\n",
      "Episode 172 return 2966.0000003 discounted reward 31.7207173\n",
      "Episode 173 return 3098.0000003 discounted reward 12.3641813\n",
      "Episode 174 return 3206.0000003 discounted reward 19.7252263\n",
      "Episode 175 return 3398.0000003 discounted reward 22.6420413\n",
      "Episode 176 return 2572.0000003 discounted reward 9.7514223\n",
      "Episode 177 return 3080.0000003 discounted reward 13.2110423\n",
      "Episode 178 return 3452.0000003 discounted reward 36.1075653\n",
      "Episode 179 return 3280.0000003 discounted reward 15.3292463\n",
      "Episode 180 return 2932.0000003 discounted reward 25.3711303\n",
      "Episode 181 return 3346.0000003 discounted reward 30.8838103\n",
      "Episode 182 return 3066.0000003 discounted reward 29.0954793\n",
      "Episode 183 return 3348.0000003 discounted reward 59.8476913\n",
      "Episode 184 return 3240.0000003 discounted reward 51.9197723\n",
      "Episode 185 return 3032.0000003 discounted reward 18.5745103\n",
      "Episode 186 return 3134.0000003 discounted reward 38.8891833\n",
      "Episode 187 return 3074.0000003 discounted reward 18.7175313\n",
      "Episode 188 return 3316.0000003 discounted reward 15.7609603\n",
      "Episode 189 return 2920.0000003 discounted reward 17.6537063\n",
      "Episode 190 return 2900.0000003 discounted reward 25.6317673\n",
      "Episode 191 return 3262.0000003 discounted reward 15.9813963\n",
      "Episode 192 return 2848.0000003 discounted reward 26.8515173\n",
      "Episode 193 return 2950.0000003 discounted reward 11.1900503\n",
      "Episode 194 return 2588.0000003 discounted reward 20.3406483\n",
      "Episode 195 return 2810.0000003 discounted reward 18.4792283\n",
      "Episode 196 return 3048.0000003 discounted reward 19.8692663\n",
      "Episode 197 return 3124.0000003 discounted reward 20.1927923\n",
      "Episode 198 return 2674.0000003 discounted reward 14.8301423\n",
      "Episode 199 return 2700.0000003 discounted reward 10.1241443\n",
      "Episode 200 return 3132.0000003 discounted reward 15.2144043\n",
      "[array([-0.54110072,  0.13104214]), array([ 0.27808481, -0.77596607]), array([ 0.34879072, -2.7048001 ]), array([-1.72043684, -3.12128661]), array([ 0.04108753, -6.45521586])]\n",
      "[array([0., 1.]), array([1., 0.]), array([1., 0.]), array([1., 0.]), array([1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "env_name = 'NChain-v0'\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/NChain-odrpo/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "\n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyWass(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 200\n",
    "batch_eps = 1\n",
    "max_steps = 1000\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "all_values = np.zeros(sta_num)\n",
    "learning_rate = 0.05\n",
    "\n",
    "\n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        value_observe = all_values[observe]\n",
    "        value_next_observe = all_values[next_observe]\n",
    "        # update advantage\n",
    "        all_advantages[observe][action] = all_advantages[observe][action]*(1-learning_rate) + (reward + gamma*value_next_observe - value_observe)*learning_rate \n",
    "        # update value\n",
    "        all_values[observe] = all_values[observe]*(1-learning_rate) + (reward + gamma*value_next_observe)*learning_rate \n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))\n",
    "print(all_advantages)\n",
    "print(policy.get_policy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO (online) + online human interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return 1482.0000003 discounted reward 13.2704933\n",
      "Episode 2 return 1176.0000003 discounted reward 9.6053123\n",
      "Episode 3 return 1390.0000003 discounted reward 15.0094063\n",
      "Episode 4 return 1268.0000003 discounted reward 12.1881123\n",
      "Episode 5 return 1436.0000003 discounted reward 13.7401513\n",
      "Episode 6 return 3460.0000003 discounted reward 42.4595313\n",
      "Episode 7 return 4004.0000003 discounted reward 14.2123713\n",
      "Episode 8 return 3416.0000003 discounted reward 33.5322783\n",
      "Episode 9 return 3618.0000003 discounted reward 29.3253823\n",
      "Episode 10 return 3290.0000003 discounted reward 23.5436953\n",
      "Episode 11 return 3904.0000003 discounted reward 11.3509533\n",
      "Episode 12 return 3586.0000003 discounted reward 8.0207883\n",
      "Episode 13 return 3222.0000003 discounted reward 15.7648853\n",
      "Episode 14 return 3662.0000003 discounted reward 24.0952193\n",
      "Episode 15 return 3386.0000003 discounted reward 11.6965453\n",
      "Episode 16 return 3556.0000003 discounted reward 10.0271093\n",
      "Episode 17 return 3414.0000003 discounted reward 32.2568493\n",
      "Episode 18 return 3534.0000003 discounted reward 11.7042393\n",
      "Episode 19 return 3358.0000003 discounted reward 21.6153383\n",
      "Episode 20 return 3940.0000003 discounted reward 30.6433813\n",
      "Episode 21 return 3606.0000003 discounted reward 21.6124033\n",
      "Episode 22 return 3384.0000003 discounted reward 12.1994213\n",
      "Episode 23 return 3832.0000003 discounted reward 25.7276353\n",
      "Episode 24 return 3274.0000003 discounted reward 29.9118283\n",
      "Episode 25 return 3308.0000003 discounted reward 29.8802993\n",
      "Episode 26 return 4020.0000003 discounted reward 33.7564353\n",
      "Episode 27 return 3286.0000003 discounted reward 7.7679243\n",
      "Episode 28 return 3428.0000003 discounted reward 19.6431243\n",
      "Episode 29 return 3458.0000003 discounted reward 31.7589183\n",
      "Episode 30 return 3484.0000003 discounted reward 40.3795373\n",
      "Episode 31 return 3848.0000003 discounted reward 19.5256143\n",
      "Episode 32 return 4000.0000003 discounted reward 27.0700913\n",
      "Episode 33 return 3802.0000003 discounted reward 29.2707563\n",
      "Episode 34 return 3794.0000003 discounted reward 37.8625543\n",
      "Episode 35 return 3102.0000003 discounted reward 29.9798553\n",
      "Episode 36 return 3498.0000003 discounted reward 8.0375423\n",
      "Episode 37 return 3440.0000003 discounted reward 17.1605713\n",
      "Episode 38 return 3910.0000003 discounted reward 35.7369213\n",
      "Episode 39 return 4022.0000003 discounted reward 19.5432143\n",
      "Episode 40 return 3272.0000003 discounted reward 29.3338513\n",
      "Episode 41 return 3804.0000003 discounted reward 14.5969733\n",
      "Episode 42 return 3584.0000003 discounted reward 8.8258983\n",
      "Episode 43 return 3880.0000003 discounted reward 15.4134743\n",
      "Episode 44 return 3732.0000003 discounted reward 27.1611943\n",
      "Episode 45 return 3956.0000003 discounted reward 26.2758713\n",
      "Episode 46 return 2976.0000003 discounted reward 30.2296273\n",
      "Episode 47 return 3646.0000003 discounted reward 23.1563463\n",
      "Episode 48 return 3254.0000003 discounted reward 37.8096293\n",
      "Episode 49 return 3650.0000003 discounted reward 43.4833693\n",
      "Episode 50 return 4308.0000003 discounted reward 14.9314643\n",
      "Episode 51 return 3436.0000003 discounted reward 32.0148553\n",
      "Episode 52 return 3304.0000003 discounted reward 25.7449733\n",
      "Episode 53 return 4016.0000003 discounted reward 14.6217513\n",
      "Episode 54 return 3500.0000003 discounted reward 25.6026003\n",
      "Episode 55 return 3490.0000003 discounted reward 12.9931663\n",
      "Episode 56 return 4220.0000003 discounted reward 25.5737093\n",
      "Episode 57 return 4068.0000003 discounted reward 25.3138183\n",
      "Episode 58 return 3872.0000003 discounted reward 23.4277393\n",
      "Episode 59 return 3514.0000003 discounted reward 13.5257143\n",
      "Episode 60 return 3668.0000003 discounted reward 47.0053453\n",
      "Episode 61 return 3632.0000003 discounted reward 34.9579563\n",
      "Episode 62 return 3968.0000003 discounted reward 11.1153143\n",
      "Episode 63 return 3812.0000003 discounted reward 17.0750683\n",
      "Episode 64 return 3414.0000003 discounted reward 18.0017133\n",
      "Episode 65 return 4010.0000003 discounted reward 23.8060833\n",
      "Episode 66 return 3548.0000003 discounted reward 34.9231903\n",
      "Episode 67 return 4114.0000003 discounted reward 37.9473693\n",
      "Episode 68 return 3396.0000003 discounted reward 20.5272063\n",
      "Episode 69 return 3582.0000003 discounted reward 14.3329873\n",
      "Episode 70 return 3548.0000003 discounted reward 16.5122603\n",
      "Episode 71 return 3452.0000003 discounted reward 19.4420143\n",
      "Episode 72 return 3794.0000003 discounted reward 8.6916703\n",
      "Episode 73 return 3622.0000003 discounted reward 41.3710043\n",
      "Episode 74 return 4014.0000003 discounted reward 16.3830063\n",
      "Episode 75 return 3434.0000003 discounted reward 7.1698843\n",
      "Episode 76 return 3136.0000003 discounted reward 24.9010193\n",
      "Episode 77 return 3774.0000003 discounted reward 28.1236113\n",
      "Episode 78 return 3674.0000003 discounted reward 22.5867493\n",
      "Episode 79 return 3280.0000003 discounted reward 36.2264813\n",
      "Episode 80 return 3196.0000003 discounted reward 44.3555083\n",
      "Episode 81 return 3946.0000003 discounted reward 43.8059883\n",
      "Episode 82 return 3648.0000003 discounted reward 12.5336353\n",
      "Episode 83 return 3680.0000003 discounted reward 21.0671593\n",
      "Episode 84 return 3622.0000003 discounted reward 11.8790293\n",
      "Episode 85 return 3874.0000003 discounted reward 12.8974133\n",
      "Episode 86 return 3250.0000003 discounted reward 27.0007263\n",
      "Episode 87 return 4122.0000003 discounted reward 45.6319613\n",
      "Episode 88 return 3866.0000003 discounted reward 40.5760563\n",
      "Episode 89 return 3854.0000003 discounted reward 34.5043683\n",
      "Episode 90 return 3810.0000003 discounted reward 21.6950853\n",
      "Episode 91 return 3654.0000003 discounted reward 16.9661853\n",
      "Episode 92 return 3252.0000003 discounted reward 25.6129493\n",
      "Episode 93 return 3712.0000003 discounted reward 48.7350503\n",
      "Episode 94 return 3654.0000003 discounted reward 20.1893483\n",
      "Episode 95 return 3790.0000003 discounted reward 41.4514123\n",
      "Episode 96 return 3710.0000003 discounted reward 17.7459803\n",
      "Episode 97 return 3686.0000003 discounted reward 8.0256203\n",
      "Episode 98 return 4142.0000003 discounted reward 35.6259203\n",
      "Episode 99 return 3682.0000003 discounted reward 19.0614353\n",
      "Episode 100 return 3630.0000003 discounted reward 27.3300343\n",
      "Episode 101 return 3448.0000003 discounted reward 7.5516023\n",
      "Episode 102 return 3626.0000003 discounted reward 46.7924343\n",
      "Episode 103 return 3880.0000003 discounted reward 37.6750623\n",
      "Episode 104 return 3320.0000003 discounted reward 11.4164933\n",
      "Episode 105 return 3508.0000003 discounted reward 12.9622933\n",
      "Episode 106 return 3770.0000003 discounted reward 20.3570843\n",
      "Episode 107 return 3634.0000003 discounted reward 8.6392703\n",
      "Episode 108 return 3628.0000003 discounted reward 13.2823473\n",
      "Episode 109 return 4066.0000003 discounted reward 27.1920993\n",
      "Episode 110 return 3352.0000003 discounted reward 11.8411113\n",
      "Episode 111 return 3700.0000003 discounted reward 13.8906553\n",
      "Episode 112 return 3648.0000003 discounted reward 46.0429773\n",
      "Episode 113 return 4202.0000003 discounted reward 28.8447893\n",
      "Episode 114 return 3292.0000003 discounted reward 18.5756393\n",
      "Episode 115 return 3746.0000003 discounted reward 41.4662363\n",
      "Episode 116 return 3774.0000003 discounted reward 26.1667933\n",
      "Episode 117 return 3446.0000003 discounted reward 16.3963833\n",
      "Episode 118 return 4002.0000003 discounted reward 11.9651143\n",
      "Episode 119 return 3818.0000003 discounted reward 46.4458023\n",
      "Episode 120 return 3388.0000003 discounted reward 23.6979883\n",
      "Episode 121 return 3480.0000003 discounted reward 18.1220953\n",
      "Episode 122 return 3400.0000003 discounted reward 19.0643153\n",
      "Episode 123 return 3726.0000003 discounted reward 31.1153593\n",
      "Episode 124 return 3564.0000003 discounted reward 7.1251013\n",
      "Episode 125 return 3732.0000003 discounted reward 20.2291713\n",
      "Episode 126 return 4016.0000003 discounted reward 21.6008173\n",
      "Episode 127 return 3410.0000003 discounted reward 9.6203143\n",
      "Episode 128 return 3318.0000003 discounted reward 12.8842293\n",
      "Episode 129 return 3806.0000003 discounted reward 11.7242603\n",
      "Episode 130 return 3314.0000003 discounted reward 15.6521853\n",
      "Episode 131 return 3298.0000003 discounted reward 17.5022743\n",
      "Episode 132 return 4216.0000003 discounted reward 17.6862423\n",
      "Episode 133 return 3520.0000003 discounted reward 20.5069923\n",
      "Episode 134 return 3828.0000003 discounted reward 22.3378923\n",
      "Episode 135 return 3930.0000003 discounted reward 57.7892583\n",
      "Episode 136 return 3678.0000003 discounted reward 36.8425113\n",
      "Episode 137 return 3786.0000003 discounted reward 40.0141133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 138 return 4274.0000003 discounted reward 56.8401143\n",
      "Episode 139 return 3894.0000003 discounted reward 63.9801873\n",
      "Episode 140 return 3376.0000003 discounted reward 13.9344653\n",
      "Episode 141 return 3100.0000003 discounted reward 11.8269763\n",
      "Episode 142 return 4016.0000003 discounted reward 17.6920093\n",
      "Episode 143 return 3126.0000003 discounted reward 11.2599633\n",
      "Episode 144 return 4050.0000003 discounted reward 8.7559493\n",
      "Episode 145 return 3732.0000003 discounted reward 27.1779753\n",
      "Episode 146 return 3636.0000003 discounted reward 54.3151963\n",
      "Episode 147 return 3472.0000003 discounted reward 40.2058363\n",
      "Episode 148 return 3438.0000003 discounted reward 24.4493723\n",
      "Episode 149 return 3212.0000003 discounted reward 22.9611953\n",
      "Episode 150 return 3458.0000003 discounted reward 13.6181903\n",
      "Episode 151 return 3716.0000003 discounted reward 19.5413353\n",
      "Episode 152 return 3798.0000003 discounted reward 34.3956563\n",
      "Episode 153 return 3456.0000003 discounted reward 21.4407373\n",
      "Episode 154 return 3252.0000003 discounted reward 13.8057793\n",
      "Episode 155 return 3884.0000003 discounted reward 26.5530883\n",
      "Episode 156 return 3902.0000003 discounted reward 54.6450063\n",
      "Episode 157 return 3708.0000003 discounted reward 27.5000513\n",
      "Episode 158 return 3440.0000003 discounted reward 8.8695803\n",
      "Episode 159 return 3590.0000003 discounted reward 33.7450613\n",
      "Episode 160 return 4086.0000003 discounted reward 35.7275553\n",
      "Episode 161 return 4384.0000003 discounted reward 27.0773033\n",
      "Episode 162 return 3862.0000003 discounted reward 21.3774203\n",
      "Episode 163 return 3756.0000003 discounted reward 18.7112383\n",
      "Episode 164 return 3102.0000003 discounted reward 20.3564603\n",
      "Episode 165 return 3798.0000003 discounted reward 51.6052233\n",
      "Episode 166 return 3314.0000003 discounted reward 10.5838143\n",
      "Episode 167 return 4034.0000003 discounted reward 23.5372863\n",
      "Episode 168 return 3824.0000003 discounted reward 24.7936923\n",
      "Episode 169 return 3720.0000003 discounted reward 13.5272643\n",
      "Episode 170 return 4126.0000003 discounted reward 49.1384833\n",
      "Episode 171 return 3806.0000003 discounted reward 28.6540803\n",
      "Episode 172 return 3830.0000003 discounted reward 16.1396283\n",
      "Episode 173 return 3826.0000003 discounted reward 39.5140493\n",
      "Episode 174 return 3800.0000003 discounted reward 21.5771603\n",
      "Episode 175 return 3940.0000003 discounted reward 26.8454273\n",
      "Episode 176 return 3356.0000003 discounted reward 24.9001173\n",
      "Episode 177 return 3280.0000003 discounted reward 44.8286043\n",
      "Episode 178 return 4322.0000003 discounted reward 19.2998483\n",
      "Episode 179 return 3876.0000003 discounted reward 48.6023493\n",
      "Episode 180 return 4122.0000003 discounted reward 18.2483673\n",
      "Episode 181 return 3844.0000003 discounted reward 42.9114583\n",
      "Episode 182 return 3640.0000003 discounted reward 26.1574103\n",
      "Episode 183 return 3676.0000003 discounted reward 37.0746063\n",
      "Episode 184 return 3662.0000003 discounted reward 22.5310683\n",
      "Episode 185 return 3408.0000003 discounted reward 20.0155353\n",
      "Episode 186 return 3708.0000003 discounted reward 28.8861993\n",
      "Episode 187 return 3508.0000003 discounted reward 24.2412073\n",
      "Episode 188 return 3882.0000003 discounted reward 19.8676523\n",
      "Episode 189 return 3192.0000003 discounted reward 18.9185213\n",
      "Episode 190 return 4216.0000003 discounted reward 38.8412923\n",
      "Episode 191 return 4294.0000003 discounted reward 19.8850223\n",
      "Episode 192 return 4076.0000003 discounted reward 16.6047493\n",
      "Episode 193 return 3248.0000003 discounted reward 13.2934813\n",
      "Episode 194 return 3488.0000003 discounted reward 12.5935723\n",
      "Episode 195 return 4102.0000003 discounted reward 34.1280763\n",
      "Episode 196 return 4154.0000003 discounted reward 21.4216283\n",
      "Episode 197 return 3734.0000003 discounted reward 11.3949343\n",
      "Episode 198 return 3460.0000003 discounted reward 38.4444643\n",
      "Episode 199 return 3820.0000003 discounted reward 13.9651513\n",
      "Episode 200 return 3742.0000003 discounted reward 14.0471383\n"
     ]
    }
   ],
   "source": [
    "env_name = 'NChain-v0'\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/NChain-odrpo-online-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "\n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyWass(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 200\n",
    "batch_eps = 1\n",
    "max_steps = 1000\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "all_values = np.zeros(sta_num)\n",
    "learning_rate = 0.05\n",
    "\n",
    "human_recommendation = dict([(0,0),(1,0),(2,0),(3,0),(4,0)])\n",
    "\n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        value_observe = all_values[observe]\n",
    "        value_next_observe = all_values[next_observe]\n",
    "        # update advantage\n",
    "        all_advantages[observe][action] = all_advantages[observe][action]*(1-learning_rate) + (reward + gamma*value_next_observe - value_observe)*learning_rate \n",
    "        # update value\n",
    "        all_values[observe] = all_values[observe]*(1-learning_rate) + (reward + gamma*value_next_observe)*learning_rate \n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            #--------------- Human in the loop --------------- #\n",
    "            if human_recommendation[observe] != action: \n",
    "                all_advantages[observe][action] -= 0.1\n",
    "            else:\n",
    "                all_advantages[observe][action] += 0.1\n",
    "            #------------------------------------------------- #\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO (online) + offline human interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return 1190.0000003 discounted reward 11.4357993\n",
      "Episode 2 return 1466.0000003 discounted reward 13.0208193\n",
      "Episode 3 return 1322.0000003 discounted reward 8.5814073\n",
      "Episode 4 return 1260.0000003 discounted reward 9.3045713\n",
      "Episode 5 return 1394.0000003 discounted reward 11.8486923\n",
      "Episode 6 return 2194.0000003 discounted reward 16.5420083\n",
      "Episode 7 return 2138.0000003 discounted reward 16.0481603\n",
      "Episode 8 return 2032.0000003 discounted reward 13.4210633\n",
      "Episode 9 return 3170.0000003 discounted reward 21.3629753\n",
      "Episode 10 return 3208.0000003 discounted reward 37.8912963\n",
      "Episode 11 return 3214.0000003 discounted reward 21.7396103\n",
      "Episode 12 return 3010.0000003 discounted reward 22.0163173\n",
      "Episode 13 return 3126.0000003 discounted reward 21.6623123\n",
      "Episode 14 return 3412.0000003 discounted reward 16.8538013\n",
      "Episode 15 return 3846.0000003 discounted reward 19.0900683\n",
      "Episode 16 return 3646.0000003 discounted reward 23.5003203\n",
      "Episode 17 return 3582.0000003 discounted reward 42.6105903\n",
      "Episode 18 return 3532.0000003 discounted reward 10.5012883\n",
      "Episode 19 return 4118.0000003 discounted reward 51.3685633\n",
      "Episode 20 return 3542.0000003 discounted reward 20.2242273\n",
      "Episode 21 return 3994.0000003 discounted reward 36.2389373\n",
      "Episode 22 return 3376.0000003 discounted reward 11.2407743\n",
      "Episode 23 return 3314.0000003 discounted reward 27.8318733\n",
      "Episode 24 return 3486.0000003 discounted reward 37.0695793\n",
      "Episode 25 return 3790.0000003 discounted reward 11.4814723\n",
      "Episode 26 return 3686.0000003 discounted reward 23.4695093\n",
      "Episode 27 return 3702.0000003 discounted reward 21.8578543\n",
      "Episode 28 return 3868.0000003 discounted reward 36.8496653\n",
      "Episode 29 return 3798.0000003 discounted reward 21.4188813\n",
      "Episode 30 return 3490.0000003 discounted reward 34.5086293\n",
      "Episode 31 return 3934.0000003 discounted reward 12.8695713\n",
      "Episode 32 return 4086.0000003 discounted reward 26.4816203\n",
      "Episode 33 return 3860.0000003 discounted reward 49.3636773\n",
      "Episode 34 return 3598.0000003 discounted reward 35.0650253\n",
      "Episode 35 return 3190.0000003 discounted reward 20.1532243\n",
      "Episode 36 return 3878.0000003 discounted reward 22.5372023\n",
      "Episode 37 return 3720.0000003 discounted reward 17.5258293\n",
      "Episode 38 return 3242.0000003 discounted reward 11.5881123\n",
      "Episode 39 return 3292.0000003 discounted reward 18.9594383\n",
      "Episode 40 return 4034.0000003 discounted reward 15.7358733\n",
      "Episode 41 return 3812.0000003 discounted reward 13.6592363\n",
      "Episode 42 return 3670.0000003 discounted reward 13.7752863\n",
      "Episode 43 return 3934.0000003 discounted reward 6.9936083\n",
      "Episode 44 return 3708.0000003 discounted reward 24.5352423\n",
      "Episode 45 return 3400.0000003 discounted reward 9.9377253\n",
      "Episode 46 return 3486.0000003 discounted reward 25.3874623\n",
      "Episode 47 return 3672.0000003 discounted reward 14.9640353\n",
      "Episode 48 return 3270.0000003 discounted reward 22.0545633\n",
      "Episode 49 return 3436.0000003 discounted reward 32.4345323\n",
      "Episode 50 return 3862.0000003 discounted reward 6.6380913\n",
      "Episode 51 return 3938.0000003 discounted reward 9.5062673\n",
      "Episode 52 return 3636.0000003 discounted reward 23.2230553\n",
      "Episode 53 return 3984.0000003 discounted reward 59.9016333\n",
      "Episode 54 return 3182.0000003 discounted reward 24.4249633\n",
      "Episode 55 return 3790.0000003 discounted reward 34.2238443\n",
      "Episode 56 return 3288.0000003 discounted reward 19.2111223\n",
      "Episode 57 return 4450.0000003 discounted reward 15.5058963\n",
      "Episode 58 return 3532.0000003 discounted reward 31.0818933\n",
      "Episode 59 return 3704.0000003 discounted reward 21.2398053\n",
      "Episode 60 return 3912.0000003 discounted reward 18.8572593\n",
      "Episode 61 return 3478.0000003 discounted reward 23.5469903\n",
      "Episode 62 return 3624.0000003 discounted reward 36.5493403\n",
      "Episode 63 return 3928.0000003 discounted reward 40.5627233\n",
      "Episode 64 return 3516.0000003 discounted reward 23.6236453\n",
      "Episode 65 return 3744.0000003 discounted reward 22.5580373\n",
      "Episode 66 return 3546.0000003 discounted reward 11.5693903\n",
      "Episode 67 return 3566.0000003 discounted reward 23.5095693\n",
      "Episode 68 return 3660.0000003 discounted reward 14.7394803\n",
      "Episode 69 return 3528.0000003 discounted reward 12.9477913\n",
      "Episode 70 return 3952.0000003 discounted reward 30.1902943\n",
      "Episode 71 return 3336.0000003 discounted reward 14.8415593\n",
      "Episode 72 return 3998.0000003 discounted reward 10.1624123\n",
      "Episode 73 return 3570.0000003 discounted reward 15.9415053\n",
      "Episode 74 return 3568.0000003 discounted reward 28.6576543\n",
      "Episode 75 return 3310.0000003 discounted reward 31.5921403\n",
      "Episode 76 return 4060.0000003 discounted reward 35.6547263\n",
      "Episode 77 return 3706.0000003 discounted reward 29.0469823\n",
      "Episode 78 return 4120.0000003 discounted reward 27.4502663\n",
      "Episode 79 return 3502.0000003 discounted reward 13.4748993\n",
      "Episode 80 return 3154.0000003 discounted reward 47.4664523\n",
      "Episode 81 return 2886.0000003 discounted reward 20.0418003\n",
      "Episode 82 return 2882.0000003 discounted reward 15.5732513\n",
      "Episode 83 return 3260.0000003 discounted reward 16.7123093\n",
      "Episode 84 return 3094.0000003 discounted reward 25.6839013\n",
      "Episode 85 return 3032.0000003 discounted reward 38.0217703\n",
      "Episode 86 return 2772.0000003 discounted reward 17.1529523\n",
      "Episode 87 return 3038.0000003 discounted reward 32.6720163\n",
      "Episode 88 return 3080.0000003 discounted reward 15.9973413\n",
      "Episode 89 return 3356.0000003 discounted reward 16.6410803\n",
      "Episode 90 return 3644.0000003 discounted reward 34.4388663\n",
      "Episode 91 return 3842.0000003 discounted reward 10.7236803\n",
      "Episode 92 return 4030.0000003 discounted reward 42.6182873\n",
      "Episode 93 return 3850.0000003 discounted reward 29.9912423\n",
      "Episode 94 return 3618.0000003 discounted reward 22.4187673\n",
      "Episode 95 return 3420.0000003 discounted reward 31.4820023\n",
      "Episode 96 return 3954.0000003 discounted reward 49.5321383\n",
      "Episode 97 return 3958.0000003 discounted reward 27.7909423\n",
      "Episode 98 return 3578.0000003 discounted reward 35.3088433\n",
      "Episode 99 return 3132.0000003 discounted reward 15.5234423\n",
      "Episode 100 return 3396.0000003 discounted reward 34.8051503\n",
      "Episode 101 return 3504.0000003 discounted reward 27.6457173\n",
      "Episode 102 return 3656.0000003 discounted reward 15.2337543\n",
      "Episode 103 return 3232.0000003 discounted reward 28.9359223\n",
      "Episode 104 return 3364.0000003 discounted reward 37.1198633\n",
      "Episode 105 return 3494.0000003 discounted reward 49.0962513\n",
      "Episode 106 return 3874.0000003 discounted reward 12.7128193\n",
      "Episode 107 return 3920.0000003 discounted reward 39.9702143\n",
      "Episode 108 return 3696.0000003 discounted reward 11.2049303\n",
      "Episode 109 return 3900.0000003 discounted reward 28.6707653\n",
      "Episode 110 return 3456.0000003 discounted reward 25.9325923\n",
      "Episode 111 return 3422.0000003 discounted reward 27.0406593\n",
      "Episode 112 return 3632.0000003 discounted reward 24.6331693\n",
      "Episode 113 return 3602.0000003 discounted reward 29.0303353\n",
      "Episode 114 return 3548.0000003 discounted reward 42.5477373\n",
      "Episode 115 return 4034.0000003 discounted reward 29.4817983\n",
      "Episode 116 return 3532.0000003 discounted reward 34.1943953\n",
      "Episode 117 return 3862.0000003 discounted reward 11.3169093\n",
      "Episode 118 return 3468.0000003 discounted reward 30.5690623\n",
      "Episode 119 return 3760.0000003 discounted reward 11.0817233\n",
      "Episode 120 return 3368.0000003 discounted reward 27.5376773\n",
      "Episode 121 return 3298.0000003 discounted reward 17.7213863\n",
      "Episode 122 return 3460.0000003 discounted reward 13.6375793\n",
      "Episode 123 return 3996.0000003 discounted reward 12.8719023\n",
      "Episode 124 return 3728.0000003 discounted reward 57.9618303\n",
      "Episode 125 return 3370.0000003 discounted reward 13.0040163\n",
      "Episode 126 return 4112.0000003 discounted reward 34.8067023\n",
      "Episode 127 return 3832.0000003 discounted reward 24.8414943\n",
      "Episode 128 return 3522.0000003 discounted reward 16.9732133\n",
      "Episode 129 return 3518.0000003 discounted reward 21.3624913\n",
      "Episode 130 return 3720.0000003 discounted reward 25.7501833\n",
      "Episode 131 return 3490.0000003 discounted reward 16.0055043\n",
      "Episode 132 return 3662.0000003 discounted reward 27.0541073\n",
      "Episode 133 return 3796.0000003 discounted reward 18.2608523\n",
      "Episode 134 return 3362.0000003 discounted reward 19.9754763\n",
      "Episode 135 return 3756.0000003 discounted reward 21.4170703\n",
      "Episode 136 return 3856.0000003 discounted reward 25.8627643\n",
      "Episode 137 return 3596.0000003 discounted reward 6.7849213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 138 return 3374.0000003 discounted reward 18.1566443\n",
      "Episode 139 return 3562.0000003 discounted reward 62.8372213\n",
      "Episode 140 return 3384.0000003 discounted reward 29.4159933\n",
      "Episode 141 return 3634.0000003 discounted reward 24.2437293\n",
      "Episode 142 return 3884.0000003 discounted reward 21.0375873\n",
      "Episode 143 return 3668.0000003 discounted reward 14.6371293\n",
      "Episode 144 return 3598.0000003 discounted reward 28.8574253\n",
      "Episode 145 return 3246.0000003 discounted reward 36.7610593\n",
      "Episode 146 return 3884.0000003 discounted reward 41.7773043\n",
      "Episode 147 return 3460.0000003 discounted reward 20.3706863\n",
      "Episode 148 return 3460.0000003 discounted reward 22.0905703\n",
      "Episode 149 return 3108.0000003 discounted reward 41.3440603\n",
      "Episode 150 return 3532.0000003 discounted reward 28.9042753\n",
      "Episode 151 return 3224.0000003 discounted reward 26.5687573\n",
      "Episode 152 return 3578.0000003 discounted reward 12.9340383\n",
      "Episode 153 return 3780.0000003 discounted reward 10.0720233\n",
      "Episode 154 return 3522.0000003 discounted reward 24.7446143\n",
      "Episode 155 return 4238.0000003 discounted reward 16.2418233\n",
      "Episode 156 return 3520.0000003 discounted reward 9.9991323\n",
      "Episode 157 return 3370.0000003 discounted reward 9.4882723\n",
      "Episode 158 return 3780.0000003 discounted reward 30.4308913\n",
      "Episode 159 return 3706.0000003 discounted reward 34.9186563\n",
      "Episode 160 return 3400.0000003 discounted reward 14.5406933\n",
      "Episode 161 return 3356.0000003 discounted reward 18.7944613\n",
      "Episode 162 return 3876.0000003 discounted reward 38.0343633\n",
      "Episode 163 return 3808.0000003 discounted reward 37.5871893\n",
      "Episode 164 return 4106.0000003 discounted reward 9.7911343\n",
      "Episode 165 return 3338.0000003 discounted reward 21.9545993\n",
      "Episode 166 return 3590.0000003 discounted reward 21.8662383\n",
      "Episode 167 return 3610.0000003 discounted reward 17.5854203\n",
      "Episode 168 return 3530.0000003 discounted reward 26.5223593\n",
      "Episode 169 return 3712.0000003 discounted reward 31.9254963\n",
      "Episode 170 return 4098.0000003 discounted reward 46.3321283\n",
      "Episode 171 return 3658.0000003 discounted reward 20.3864513\n",
      "Episode 172 return 3452.0000003 discounted reward 35.7537563\n",
      "Episode 173 return 4070.0000003 discounted reward 38.5614253\n",
      "Episode 174 return 4006.0000003 discounted reward 34.8444473\n",
      "Episode 175 return 3652.0000003 discounted reward 18.5171963\n",
      "Episode 176 return 3512.0000003 discounted reward 34.5030123\n",
      "Episode 177 return 3824.0000003 discounted reward 25.7569383\n",
      "Episode 178 return 3728.0000003 discounted reward 7.9330223\n",
      "Episode 179 return 3664.0000003 discounted reward 24.7801943\n",
      "Episode 180 return 3822.0000003 discounted reward 33.7767963\n",
      "Episode 181 return 3542.0000003 discounted reward 32.8995353\n",
      "Episode 182 return 3666.0000003 discounted reward 8.3550423\n",
      "Episode 183 return 3838.0000003 discounted reward 26.1927803\n",
      "Episode 184 return 3938.0000003 discounted reward 18.1176253\n",
      "Episode 185 return 3874.0000003 discounted reward 16.7403453\n",
      "Episode 186 return 3392.0000003 discounted reward 23.8415633\n",
      "Episode 187 return 3570.0000003 discounted reward 19.1573193\n",
      "Episode 188 return 3856.0000003 discounted reward 49.6393983\n",
      "Episode 189 return 4044.0000003 discounted reward 40.0932183\n",
      "Episode 190 return 3406.0000003 discounted reward 16.7956163\n",
      "Episode 191 return 3768.0000003 discounted reward 47.6017503\n",
      "Episode 192 return 3340.0000003 discounted reward 9.3951953\n",
      "Episode 193 return 3662.0000003 discounted reward 25.2857323\n",
      "Episode 194 return 3458.0000003 discounted reward 13.6116243\n",
      "Episode 195 return 3956.0000003 discounted reward 57.4337693\n",
      "Episode 196 return 3320.0000003 discounted reward 38.1451843\n",
      "Episode 197 return 3806.0000003 discounted reward 52.7846533\n",
      "Episode 198 return 3956.0000003 discounted reward 37.2193883\n",
      "Episode 199 return 3646.0000003 discounted reward 34.7175803\n",
      "Episode 200 return 3884.0000003 discounted reward 41.5563903\n"
     ]
    }
   ],
   "source": [
    "env_name = 'NChain-v0'\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/NChain-odrpo-offline-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "\n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyWass(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 200\n",
    "batch_eps = 1\n",
    "max_steps = 1000\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "all_values = np.zeros(sta_num)\n",
    "learning_rate = 0.05\n",
    "\n",
    "\n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        value_observe = all_values[observe]\n",
    "        value_next_observe = all_values[next_observe]\n",
    "        # update advantage\n",
    "        all_advantages[observe][action] = all_advantages[observe][action]*(1-learning_rate) + (reward + gamma*value_next_observe - value_observe)*learning_rate \n",
    "        # update value\n",
    "        all_values[observe] = all_values[observe]*(1-learning_rate) + (reward + gamma*value_next_observe)*learning_rate \n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "        \n",
    "    # human modifies the advantage\n",
    "    all_advantages[0][0] += 0.1\n",
    "    all_advantages[1][0] += 0.1\n",
    "    all_advantages[2][0] += 0.1\n",
    "    all_advantages[3][0] += 0.1\n",
    "    all_advantages[4][0] += 0.1\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
