{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import time\n",
    "import csv\n",
    "import gym_gridworld\n",
    "import itertools\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move to Yellow Room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 1 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 2 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 3 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 4 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 5 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 6 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 7 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 8 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 9 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 10 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 11 return 70.0000003 discounted reward -5.3369733\n",
      "Episode 12 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 13 return 78.0000003 discounted reward 0.8324803\n",
      "Episode 14 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 15 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 16 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 17 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 18 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 19 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 20 return 51.0000003 discounted reward -9.3700943\n",
      "Episode 21 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 22 return 75.0000003 discounted reward -2.1031223\n",
      "Episode 23 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 24 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 25 return 53.0000003 discounted reward -9.2223383\n",
      "Episode 26 return 70.0000003 discounted reward -5.3369733\n",
      "Episode 27 return 70.0000003 discounted reward -5.3369733\n",
      "Episode 28 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 29 return 69.0000003 discounted reward -5.8032753\n",
      "Episode 30 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 31 return 71.0000003 discounted reward -4.8188583\n",
      "Episode 32 return 58.0000003 discounted reward -8.6830233\n",
      "Episode 33 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 34 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 35 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 36 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 37 return 72.0000003 discounted reward -4.2431763\n",
      "Episode 38 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 39 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 40 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 41 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 42 return 73.0000003 discounted reward -3.6035293\n",
      "Episode 43 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 44 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 45 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 46 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 47 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 48 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 49 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 50 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 51 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 52 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 53 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 54 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 55 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 56 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 57 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 58 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 59 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 60 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 61 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 62 return 70.0000003 discounted reward -5.3369733\n",
      "Episode 63 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 64 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 65 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 66 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 67 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 68 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 69 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 70 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 71 return 78.0000003 discounted reward 0.8324803\n",
      "Episode 72 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 73 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 74 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 75 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 76 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 77 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 78 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 79 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 80 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 81 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 82 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 83 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 84 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 85 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 86 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 87 return 76.0000003 discounted reward -1.2256913\n",
      "Episode 88 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 89 return 71.0000003 discounted reward -4.8188583\n",
      "Episode 90 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 91 return 54.0000003 discounted reward -9.1359323\n",
      "Episode 92 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 93 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 94 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 95 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 96 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 97 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 98 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 99 return 93.0000003 discounted reward 42.6126593\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"GridWorld-v0\")\n",
    "file_name = \"log_files/GridWorld-q-learning/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "\n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 50):\n",
    "    Q = defaultdict(lambda: np.zeros(env.n_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.n_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human in the Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 1 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 2 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 3 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 4 return 74.0000003 discounted reward -2.8928103\n",
      "Episode 5 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 6 return 78.0000003 discounted reward 0.8324803\n",
      "Episode 7 return 77.0000003 discounted reward -0.2507683\n",
      "Episode 8 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 9 return 65.0000003 discounted reward -7.2465293\n",
      "Episode 10 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 11 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 12 return 64.0000003 discounted reward -7.5218763\n",
      "Episode 13 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 14 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 15 return 74.0000003 discounted reward -2.8928103\n",
      "Episode 16 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 17 return 77.0000003 discounted reward -0.2507683\n",
      "Episode 18 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 19 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 20 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 21 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 22 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 23 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 24 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 25 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 26 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 27 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 28 return 66.0000003 discounted reward -6.9405883\n",
      "Episode 29 return 57.0000003 discounted reward -8.8147213\n",
      "Episode 30 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 31 return 73.0000003 discounted reward -3.6035293\n",
      "Episode 32 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 33 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 34 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 35 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 36 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 37 return 80.0000003 discounted reward 3.3734323\n",
      "Episode 38 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 39 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 40 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 41 return 78.0000003 discounted reward 0.8324803\n",
      "Episode 42 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 43 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 44 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 45 return 67.0000003 discounted reward -6.6006533\n",
      "Episode 46 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 47 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 48 return 61.0000003 discounted reward -8.1934483\n",
      "Episode 49 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 50 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 51 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 52 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 53 return 72.0000003 discounted reward -4.2431763\n",
      "Episode 54 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 55 return 73.0000003 discounted reward -3.6035293\n",
      "Episode 56 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 57 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 58 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 59 return 65.0000003 discounted reward -7.2465293\n",
      "Episode 60 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 61 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 62 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 63 return 61.0000003 discounted reward -8.1934483\n",
      "Episode 64 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 65 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 66 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 67 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 68 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 69 return 80.0000003 discounted reward 3.3734323\n",
      "Episode 70 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 71 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 72 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 73 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 74 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 75 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 76 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 77 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 78 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 79 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 80 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 81 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 82 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 83 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 84 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 85 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 86 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 87 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 88 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 89 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 90 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 91 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 92 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 93 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 94 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 95 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 96 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 97 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 98 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 99 return 81.0000003 discounted reward 4.8593693\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"GridWorld-v0\")\n",
    "file_name = \"log_files/GridWorld-q-learning-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "    \n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 50):\n",
    "    Q = defaultdict(lambda: np.zeros(env.n_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.n_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "        # human modifies the Q\n",
    "        # left red room\n",
    "        Q[0][2] += 1\n",
    "        Q[8][2] += 1\n",
    "        Q[16][2] += 1\n",
    "        Q[24][1] += 1\n",
    "        Q[32][0] += 1\n",
    "        Q[40][0] += 1\n",
    "        Q[48][0] += 1\n",
    "        \n",
    "        Q[1][2] += 1\n",
    "        Q[9][2] += 1\n",
    "        Q[17][2] += 1\n",
    "        Q[25][1] += 1\n",
    "        Q[33][0] += 1\n",
    "        Q[41][0] += 1\n",
    "        Q[49][0] += 1\n",
    "        \n",
    "        \n",
    "        # middle path \n",
    "        Q[26][1] += 1\n",
    "        \n",
    "        # middle blue room\n",
    "        Q[3][2] += 1\n",
    "        Q[11][2] += 1\n",
    "        Q[19][2] += 1\n",
    "        Q[27][1] += 1\n",
    "        Q[35][0] += 1\n",
    "        Q[43][0] += 1\n",
    "        Q[51][0] += 1\n",
    "        \n",
    "        Q[4][2] += 1\n",
    "        Q[12][2] += 1\n",
    "        Q[20][2] += 1\n",
    "        Q[28][1] += 1\n",
    "        Q[36][0] += 1\n",
    "        Q[44][0] += 1\n",
    "        Q[52][0] += 1\n",
    "        \n",
    "        # middle path \n",
    "        Q[29][1] += 1\n",
    "        \n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return 1434.0000003 discounted reward 17.4799993\n",
      "Episode 1 return 1572.0000003 discounted reward 10.3289523\n",
      "Episode 2 return 1896.0000003 discounted reward 8.6802773\n",
      "Episode 3 return 1932.0000003 discounted reward 8.1771843\n",
      "Episode 4 return 1932.0000003 discounted reward 11.3786773\n",
      "Episode 5 return 1970.0000003 discounted reward 15.3682433\n",
      "Episode 6 return 2014.0000003 discounted reward 15.1859703\n",
      "Episode 7 return 2054.0000003 discounted reward 22.0485943\n",
      "Episode 8 return 1816.0000003 discounted reward 8.9081273\n",
      "Episode 9 return 1760.0000003 discounted reward 15.3225653\n",
      "Episode 10 return 2264.0000003 discounted reward 19.4932343\n",
      "Episode 11 return 1950.0000003 discounted reward 11.5080763\n",
      "Episode 12 return 1870.0000003 discounted reward 9.0328393\n",
      "Episode 13 return 2046.0000003 discounted reward 9.1277913\n",
      "Episode 14 return 2212.0000003 discounted reward 15.8519003\n",
      "Episode 15 return 1834.0000003 discounted reward 7.8988933\n",
      "Episode 16 return 2044.0000003 discounted reward 16.4027623\n",
      "Episode 17 return 1876.0000003 discounted reward 14.6037593\n",
      "Episode 18 return 2052.0000003 discounted reward 25.8792133\n",
      "Episode 19 return 1884.0000003 discounted reward 8.4394693\n",
      "Episode 20 return 1472.0000003 discounted reward 10.6445273\n",
      "Episode 21 return 1636.0000003 discounted reward 15.4394793\n",
      "Episode 22 return 1834.0000003 discounted reward 12.5910003\n",
      "Episode 23 return 1904.0000003 discounted reward 15.0982123\n",
      "Episode 24 return 2012.0000003 discounted reward 10.4026343\n",
      "Episode 25 return 1982.0000003 discounted reward 11.2135683\n",
      "Episode 26 return 1754.0000003 discounted reward 11.9906533\n",
      "Episode 27 return 1650.0000003 discounted reward 13.7521273\n",
      "Episode 28 return 1810.0000003 discounted reward 12.3474813\n",
      "Episode 29 return 1774.0000003 discounted reward 9.6626003\n",
      "Episode 30 return 1848.0000003 discounted reward 10.5174603\n",
      "Episode 31 return 1666.0000003 discounted reward 13.8407043\n",
      "Episode 32 return 1864.0000003 discounted reward 17.7804143\n",
      "Episode 33 return 1888.0000003 discounted reward 9.9740673\n",
      "Episode 34 return 1554.0000003 discounted reward 9.4619773\n",
      "Episode 35 return 1786.0000003 discounted reward 16.3733063\n",
      "Episode 36 return 1656.0000003 discounted reward 32.0293923\n",
      "Episode 37 return 1660.0000003 discounted reward 26.9680813\n",
      "Episode 38 return 2004.0000003 discounted reward 25.3263753\n",
      "Episode 39 return 2046.0000003 discounted reward 14.4100803\n",
      "Episode 40 return 1754.0000003 discounted reward 10.5946783\n",
      "Episode 41 return 1792.0000003 discounted reward 15.2327933\n",
      "Episode 42 return 1754.0000003 discounted reward 15.3785643\n",
      "Episode 43 return 1952.0000003 discounted reward 10.0306893\n",
      "Episode 44 return 2014.0000003 discounted reward 23.2361213\n",
      "Episode 45 return 1980.0000003 discounted reward 10.2047883\n",
      "Episode 46 return 1804.0000003 discounted reward 12.2926673\n",
      "Episode 47 return 1996.0000003 discounted reward 10.5714353\n",
      "Episode 48 return 1820.0000003 discounted reward 7.8339893\n",
      "Episode 49 return 2164.0000003 discounted reward 13.2084213\n",
      "Episode 50 return 1824.0000003 discounted reward 10.9606883\n",
      "Episode 51 return 1854.0000003 discounted reward 11.3711783\n",
      "Episode 52 return 1902.0000003 discounted reward 14.8932893\n",
      "Episode 53 return 1956.0000003 discounted reward 12.6074373\n",
      "Episode 54 return 2010.0000003 discounted reward 8.8628783\n",
      "Episode 55 return 1642.0000003 discounted reward 13.2733783\n",
      "Episode 56 return 1856.0000003 discounted reward 28.3188653\n",
      "Episode 57 return 1948.0000003 discounted reward 21.2785983\n",
      "Episode 58 return 1940.0000003 discounted reward 22.7335693\n",
      "Episode 59 return 1774.0000003 discounted reward 12.0222743\n",
      "Episode 60 return 1554.0000003 discounted reward 11.7318303\n",
      "Episode 61 return 1686.0000003 discounted reward 9.4821323\n",
      "Episode 62 return 1878.0000003 discounted reward 8.6863303\n",
      "Episode 63 return 2030.0000003 discounted reward 19.6999513\n",
      "Episode 64 return 1962.0000003 discounted reward 12.9743153\n",
      "Episode 65 return 1954.0000003 discounted reward 8.6957663\n",
      "Episode 66 return 2016.0000003 discounted reward 13.6698713\n",
      "Episode 67 return 2006.0000003 discounted reward 16.1916583\n",
      "Episode 68 return 1764.0000003 discounted reward 23.5693713\n",
      "Episode 69 return 2028.0000003 discounted reward 27.2522613\n",
      "Episode 70 return 1764.0000003 discounted reward 26.4172343\n",
      "Episode 71 return 2132.0000003 discounted reward 39.9868543\n",
      "Episode 72 return 2154.0000003 discounted reward 18.1524103\n",
      "Episode 73 return 1892.0000003 discounted reward 10.5717473\n",
      "Episode 74 return 1978.0000003 discounted reward 11.2286023\n",
      "Episode 75 return 1960.0000003 discounted reward 15.7818943\n",
      "Episode 76 return 1648.0000003 discounted reward 9.8616133\n",
      "Episode 77 return 1908.0000003 discounted reward 14.4119233\n",
      "Episode 78 return 1546.0000003 discounted reward 10.2669943\n",
      "Episode 79 return 1710.0000003 discounted reward 11.3656213\n",
      "Episode 80 return 1718.0000003 discounted reward 30.3759223\n",
      "Episode 81 return 1918.0000003 discounted reward 18.5663583\n",
      "Episode 82 return 1578.0000003 discounted reward 10.7316753\n",
      "Episode 83 return 1794.0000003 discounted reward 17.4214773\n",
      "Episode 84 return 1918.0000003 discounted reward 8.7104883\n",
      "Episode 85 return 2324.0000003 discounted reward 34.1311963\n",
      "Episode 86 return 1682.0000003 discounted reward 19.7324883\n",
      "Episode 87 return 1530.0000003 discounted reward 13.6430233\n",
      "Episode 88 return 1816.0000003 discounted reward 14.6328653\n",
      "Episode 89 return 1684.0000003 discounted reward 15.8430503\n",
      "Episode 90 return 1772.0000003 discounted reward 12.6503873\n",
      "Episode 91 return 1622.0000003 discounted reward 14.1273313\n",
      "Episode 92 return 1786.0000003 discounted reward 10.8524303\n",
      "Episode 93 return 1986.0000003 discounted reward 14.0186393\n",
      "Episode 94 return 1820.0000003 discounted reward 10.4582043\n",
      "Episode 95 return 2040.0000003 discounted reward 11.9499053\n",
      "Episode 96 return 2050.0000003 discounted reward 14.2549153\n",
      "Episode 97 return 1580.0000003 discounted reward 8.5345233\n",
      "Episode 98 return 2130.0000003 discounted reward 24.1295503\n",
      "Episode 99 return 1992.0000003 discounted reward 8.3358103\n",
      "Episode 100 return 1868.0000003 discounted reward 10.5720483\n",
      "Episode 101 return 1898.0000003 discounted reward 15.1934693\n",
      "Episode 102 return 1856.0000003 discounted reward 20.4164123\n",
      "Episode 103 return 1656.0000003 discounted reward 8.5413623\n",
      "Episode 104 return 1934.0000003 discounted reward 10.3944423\n",
      "Episode 105 return 1966.0000003 discounted reward 6.3287533\n",
      "Episode 106 return 1820.0000003 discounted reward 11.5941323\n",
      "Episode 107 return 1918.0000003 discounted reward 20.4210483\n",
      "Episode 108 return 1988.0000003 discounted reward 7.1967383\n",
      "Episode 109 return 1900.0000003 discounted reward 14.8078393\n",
      "Episode 110 return 2022.0000003 discounted reward 10.6499483\n",
      "Episode 111 return 1756.0000003 discounted reward 12.2220833\n",
      "Episode 112 return 1998.0000003 discounted reward 14.5917973\n",
      "Episode 113 return 1900.0000003 discounted reward 12.0105193\n",
      "Episode 114 return 2040.0000003 discounted reward 11.2050273\n",
      "Episode 115 return 1850.0000003 discounted reward 11.4170373\n",
      "Episode 116 return 1780.0000003 discounted reward 20.3541033\n",
      "Episode 117 return 1822.0000003 discounted reward 11.7843813\n",
      "Episode 118 return 2050.0000003 discounted reward 14.9581973\n",
      "Episode 119 return 1768.0000003 discounted reward 13.5342573\n",
      "Episode 120 return 1668.0000003 discounted reward 13.8115213\n",
      "Episode 121 return 1786.0000003 discounted reward 12.7048463\n",
      "Episode 122 return 1862.0000003 discounted reward 32.3079543\n",
      "Episode 123 return 1740.0000003 discounted reward 23.8433563\n",
      "Episode 124 return 2044.0000003 discounted reward 18.4926013\n",
      "Episode 125 return 1694.0000003 discounted reward 12.8784443\n",
      "Episode 126 return 1776.0000003 discounted reward 10.0755473\n",
      "Episode 127 return 2244.0000003 discounted reward 22.9555583\n",
      "Episode 128 return 2172.0000003 discounted reward 22.2625323\n",
      "Episode 129 return 1862.0000003 discounted reward 24.2412263\n",
      "Episode 130 return 1776.0000003 discounted reward 22.7575083\n",
      "Episode 131 return 2306.0000003 discounted reward 13.1844793\n",
      "Episode 132 return 1688.0000003 discounted reward 11.1228023\n",
      "Episode 133 return 2050.0000003 discounted reward 22.2176973\n",
      "Episode 134 return 2052.0000003 discounted reward 11.5621583\n",
      "Episode 135 return 1978.0000003 discounted reward 16.9101673\n",
      "Episode 136 return 1810.0000003 discounted reward 8.5451633\n",
      "Episode 137 return 1644.0000003 discounted reward 18.9965223\n",
      "Episode 138 return 2030.0000003 discounted reward 16.0175423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 139 return 1754.0000003 discounted reward 14.0185253\n",
      "Episode 140 return 1830.0000003 discounted reward 7.4079073\n",
      "Episode 141 return 1654.0000003 discounted reward 7.7297133\n",
      "Episode 142 return 1840.0000003 discounted reward 12.9167123\n",
      "Episode 143 return 1924.0000003 discounted reward 10.7482413\n",
      "Episode 144 return 2042.0000003 discounted reward 10.8162133\n",
      "Episode 145 return 1868.0000003 discounted reward 8.6349663\n",
      "Episode 146 return 1680.0000003 discounted reward 10.7374413\n",
      "Episode 147 return 1874.0000003 discounted reward 10.3041593\n",
      "Episode 148 return 1962.0000003 discounted reward 11.6478913\n",
      "Episode 149 return 1618.0000003 discounted reward 7.2275953\n",
      "Episode 150 return 2024.0000003 discounted reward 13.2498683\n",
      "Episode 151 return 1792.0000003 discounted reward 19.1674513\n",
      "Episode 152 return 1988.0000003 discounted reward 7.0768333\n",
      "Episode 153 return 1890.0000003 discounted reward 25.3025883\n",
      "Episode 154 return 1790.0000003 discounted reward 12.9170653\n",
      "Episode 155 return 1980.0000003 discounted reward 19.6080053\n",
      "Episode 156 return 1920.0000003 discounted reward 13.5531683\n",
      "Episode 157 return 1808.0000003 discounted reward 11.5202893\n",
      "Episode 158 return 1708.0000003 discounted reward 7.5965083\n",
      "Episode 159 return 1662.0000003 discounted reward 19.5139173\n",
      "Episode 160 return 2020.0000003 discounted reward 20.1618523\n",
      "Episode 161 return 1976.0000003 discounted reward 22.9017013\n",
      "Episode 162 return 1806.0000003 discounted reward 19.4908713\n",
      "Episode 163 return 1936.0000003 discounted reward 8.0804903\n",
      "Episode 164 return 1752.0000003 discounted reward 15.4966843\n",
      "Episode 165 return 1578.0000003 discounted reward 20.3729173\n",
      "Episode 166 return 1780.0000003 discounted reward 9.3088153\n",
      "Episode 167 return 1892.0000003 discounted reward 10.7341793\n",
      "Episode 168 return 1694.0000003 discounted reward 10.9323623\n",
      "Episode 169 return 2202.0000003 discounted reward 10.4030803\n",
      "Episode 170 return 1754.0000003 discounted reward 8.9596223\n",
      "Episode 171 return 1896.0000003 discounted reward 23.6106503\n",
      "Episode 172 return 1862.0000003 discounted reward 9.7074363\n",
      "Episode 173 return 2160.0000003 discounted reward 7.3343023\n",
      "Episode 174 return 1890.0000003 discounted reward 28.3239293\n",
      "Episode 175 return 1746.0000003 discounted reward 21.0146783\n",
      "Episode 176 return 1764.0000003 discounted reward 33.9541323\n",
      "Episode 177 return 1638.0000003 discounted reward 8.4516593\n",
      "Episode 178 return 2118.0000003 discounted reward 10.2606973\n",
      "Episode 179 return 1784.0000003 discounted reward 8.5932383\n",
      "Episode 180 return 1690.0000003 discounted reward 13.4054253\n",
      "Episode 181 return 1894.0000003 discounted reward 18.4738153\n",
      "Episode 182 return 1804.0000003 discounted reward 12.4337993\n",
      "Episode 183 return 1758.0000003 discounted reward 14.1021993\n",
      "Episode 184 return 1782.0000003 discounted reward 14.8376383\n",
      "Episode 185 return 1812.0000003 discounted reward 15.5727523\n",
      "Episode 186 return 1916.0000003 discounted reward 26.6179983\n",
      "Episode 187 return 1672.0000003 discounted reward 7.2238993\n",
      "Episode 188 return 1958.0000003 discounted reward 10.1311343\n",
      "Episode 189 return 1922.0000003 discounted reward 9.6257413\n",
      "Episode 190 return 1700.0000003 discounted reward 8.3350103\n",
      "Episode 191 return 1978.0000003 discounted reward 16.3308973\n",
      "Episode 192 return 1840.0000003 discounted reward 8.8243333\n",
      "Episode 193 return 1774.0000003 discounted reward 7.1678063\n",
      "Episode 194 return 1652.0000003 discounted reward 11.4738553\n",
      "Episode 195 return 1520.0000003 discounted reward 14.1699033\n",
      "Episode 196 return 1850.0000003 discounted reward 13.4915063\n",
      "Episode 197 return 1836.0000003 discounted reward 18.5096273\n",
      "Episode 198 return 1458.0000003 discounted reward 12.9776723\n",
      "Episode 199 return 1704.0000003 discounted reward 19.8015553\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"NChain-v0\")\n",
    "num_actions = 2\n",
    "\n",
    "file_name = \"log_files/NChain-q-learning/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "\n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 1000):\n",
    "    Q = defaultdict(lambda: np.zeros(num_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, num_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human in the Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return 1516.0000003 discounted reward 15.2382153\n",
      "Episode 1 return 1870.0000003 discounted reward 9.8216293\n",
      "Episode 2 return 1994.0000003 discounted reward 15.3234733\n",
      "Episode 3 return 2156.0000003 discounted reward 20.3731763\n",
      "Episode 4 return 1810.0000003 discounted reward 10.7708423\n",
      "Episode 5 return 1880.0000003 discounted reward 12.3377823\n",
      "Episode 6 return 1960.0000003 discounted reward 11.6536653\n",
      "Episode 7 return 1736.0000003 discounted reward 27.9075693\n",
      "Episode 8 return 2106.0000003 discounted reward 41.1794553\n",
      "Episode 9 return 1796.0000003 discounted reward 7.4491933\n",
      "Episode 10 return 1638.0000003 discounted reward 8.7556063\n",
      "Episode 11 return 1878.0000003 discounted reward 9.1340083\n",
      "Episode 12 return 1938.0000003 discounted reward 10.6561583\n",
      "Episode 13 return 1778.0000003 discounted reward 12.1791103\n",
      "Episode 14 return 1800.0000003 discounted reward 22.4383613\n",
      "Episode 15 return 1966.0000003 discounted reward 12.2937123\n",
      "Episode 16 return 1566.0000003 discounted reward 8.3380873\n",
      "Episode 17 return 1908.0000003 discounted reward 13.2637893\n",
      "Episode 18 return 1794.0000003 discounted reward 10.5017583\n",
      "Episode 19 return 1716.0000003 discounted reward 13.7548993\n",
      "Episode 20 return 1662.0000003 discounted reward 8.6701483\n",
      "Episode 21 return 1940.0000003 discounted reward 11.6645593\n",
      "Episode 22 return 1716.0000003 discounted reward 8.9619693\n",
      "Episode 23 return 1850.0000003 discounted reward 33.5583993\n",
      "Episode 24 return 2022.0000003 discounted reward 20.4338583\n",
      "Episode 25 return 1778.0000003 discounted reward 11.0139943\n",
      "Episode 26 return 1686.0000003 discounted reward 11.4368943\n",
      "Episode 27 return 2006.0000003 discounted reward 13.8698263\n",
      "Episode 28 return 1654.0000003 discounted reward 6.6051313\n",
      "Episode 29 return 1818.0000003 discounted reward 29.8374203\n",
      "Episode 30 return 1930.0000003 discounted reward 8.5933603\n",
      "Episode 31 return 2126.0000003 discounted reward 9.2338783\n",
      "Episode 32 return 1660.0000003 discounted reward 13.9717243\n",
      "Episode 33 return 1806.0000003 discounted reward 7.2624763\n",
      "Episode 34 return 2122.0000003 discounted reward 6.0848343\n",
      "Episode 35 return 1898.0000003 discounted reward 9.4226893\n",
      "Episode 36 return 2148.0000003 discounted reward 18.3763073\n",
      "Episode 37 return 2134.0000003 discounted reward 16.1069063\n",
      "Episode 38 return 1868.0000003 discounted reward 9.5232483\n",
      "Episode 39 return 1780.0000003 discounted reward 9.6953553\n",
      "Episode 40 return 1664.0000003 discounted reward 9.2533853\n",
      "Episode 41 return 1792.0000003 discounted reward 8.4028723\n",
      "Episode 42 return 1824.0000003 discounted reward 7.4588223\n",
      "Episode 43 return 1782.0000003 discounted reward 15.3258973\n",
      "Episode 44 return 1794.0000003 discounted reward 10.7542663\n",
      "Episode 45 return 1890.0000003 discounted reward 30.5600403\n",
      "Episode 46 return 1822.0000003 discounted reward 24.5366843\n",
      "Episode 47 return 1986.0000003 discounted reward 21.3692613\n",
      "Episode 48 return 1914.0000003 discounted reward 16.3078093\n",
      "Episode 49 return 1922.0000003 discounted reward 14.1048483\n",
      "Episode 50 return 1920.0000003 discounted reward 9.4337323\n",
      "Episode 51 return 1812.0000003 discounted reward 14.2860483\n",
      "Episode 52 return 2210.0000003 discounted reward 27.3432103\n",
      "Episode 53 return 1492.0000003 discounted reward 10.9626263\n",
      "Episode 54 return 1802.0000003 discounted reward 15.0766153\n",
      "Episode 55 return 1842.0000003 discounted reward 29.9822053\n",
      "Episode 56 return 1744.0000003 discounted reward 11.0880343\n",
      "Episode 57 return 1622.0000003 discounted reward 7.0263723\n",
      "Episode 58 return 2024.0000003 discounted reward 15.6490033\n",
      "Episode 59 return 1880.0000003 discounted reward 10.7853473\n",
      "Episode 60 return 1872.0000003 discounted reward 10.3131273\n",
      "Episode 61 return 1736.0000003 discounted reward 16.5519113\n",
      "Episode 62 return 1920.0000003 discounted reward 10.5464253\n",
      "Episode 63 return 1920.0000003 discounted reward 14.1758673\n",
      "Episode 64 return 1886.0000003 discounted reward 8.5119813\n",
      "Episode 65 return 1760.0000003 discounted reward 16.2609883\n",
      "Episode 66 return 1936.0000003 discounted reward 6.9810073\n",
      "Episode 67 return 1772.0000003 discounted reward 9.2861283\n",
      "Episode 68 return 2010.0000003 discounted reward 11.9303273\n",
      "Episode 69 return 2016.0000003 discounted reward 8.0784763\n",
      "Episode 70 return 1764.0000003 discounted reward 13.5973813\n",
      "Episode 71 return 1722.0000003 discounted reward 12.2702323\n",
      "Episode 72 return 1820.0000003 discounted reward 10.9216243\n",
      "Episode 73 return 1862.0000003 discounted reward 11.7343673\n",
      "Episode 74 return 1852.0000003 discounted reward 39.6824783\n",
      "Episode 75 return 1720.0000003 discounted reward 15.5014673\n",
      "Episode 76 return 2006.0000003 discounted reward 7.5060873\n",
      "Episode 77 return 2052.0000003 discounted reward 11.1588803\n",
      "Episode 78 return 2084.0000003 discounted reward 20.3173213\n",
      "Episode 79 return 1722.0000003 discounted reward 17.5974693\n",
      "Episode 80 return 1652.0000003 discounted reward 11.5233633\n",
      "Episode 81 return 1846.0000003 discounted reward 8.5985333\n",
      "Episode 82 return 1724.0000003 discounted reward 9.6554733\n",
      "Episode 83 return 1732.0000003 discounted reward 7.9136263\n",
      "Episode 84 return 1890.0000003 discounted reward 8.7165913\n",
      "Episode 85 return 1838.0000003 discounted reward 6.7441173\n",
      "Episode 86 return 1670.0000003 discounted reward 23.4751753\n",
      "Episode 87 return 1804.0000003 discounted reward 22.5538473\n",
      "Episode 88 return 1912.0000003 discounted reward 11.0278203\n",
      "Episode 89 return 2024.0000003 discounted reward 12.4746383\n",
      "Episode 90 return 1600.0000003 discounted reward 12.7405843\n",
      "Episode 91 return 2054.0000003 discounted reward 14.4243643\n",
      "Episode 92 return 1834.0000003 discounted reward 6.9271843\n",
      "Episode 93 return 1626.0000003 discounted reward 29.0607193\n",
      "Episode 94 return 1818.0000003 discounted reward 11.8707043\n",
      "Episode 95 return 1942.0000003 discounted reward 8.9099553\n",
      "Episode 96 return 1994.0000003 discounted reward 24.8393963\n",
      "Episode 97 return 1916.0000003 discounted reward 18.2901023\n",
      "Episode 98 return 1904.0000003 discounted reward 13.0296693\n",
      "Episode 99 return 1934.0000003 discounted reward 14.3538613\n",
      "Episode 100 return 1906.0000003 discounted reward 26.5838703\n",
      "Episode 101 return 1680.0000003 discounted reward 25.0192003\n",
      "Episode 102 return 1828.0000003 discounted reward 13.1385483\n",
      "Episode 103 return 1946.0000003 discounted reward 12.7646843\n",
      "Episode 104 return 2056.0000003 discounted reward 8.6117263\n",
      "Episode 105 return 1912.0000003 discounted reward 21.9862823\n",
      "Episode 106 return 2042.0000003 discounted reward 16.0062033\n",
      "Episode 107 return 1714.0000003 discounted reward 10.8418533\n",
      "Episode 108 return 2034.0000003 discounted reward 23.2606193\n",
      "Episode 109 return 1750.0000003 discounted reward 8.5128723\n",
      "Episode 110 return 1850.0000003 discounted reward 18.2995283\n",
      "Episode 111 return 1748.0000003 discounted reward 6.5238623\n",
      "Episode 112 return 2052.0000003 discounted reward 21.3535023\n",
      "Episode 113 return 1924.0000003 discounted reward 14.8858633\n",
      "Episode 114 return 1934.0000003 discounted reward 14.5873683\n",
      "Episode 115 return 1530.0000003 discounted reward 13.6289893\n",
      "Episode 116 return 1744.0000003 discounted reward 13.7751713\n",
      "Episode 117 return 1618.0000003 discounted reward 16.0663463\n",
      "Episode 118 return 1872.0000003 discounted reward 8.3145623\n",
      "Episode 119 return 1770.0000003 discounted reward 8.6512743\n",
      "Episode 120 return 1726.0000003 discounted reward 12.8332933\n",
      "Episode 121 return 1990.0000003 discounted reward 24.0862423\n",
      "Episode 122 return 2008.0000003 discounted reward 27.5838413\n",
      "Episode 123 return 2030.0000003 discounted reward 14.9698533\n",
      "Episode 124 return 1888.0000003 discounted reward 26.9263603\n",
      "Episode 125 return 1604.0000003 discounted reward 17.0558243\n",
      "Episode 126 return 1712.0000003 discounted reward 10.0884483\n",
      "Episode 127 return 1936.0000003 discounted reward 6.3932663\n",
      "Episode 128 return 1914.0000003 discounted reward 11.4391503\n",
      "Episode 129 return 2068.0000003 discounted reward 18.7449693\n",
      "Episode 130 return 1850.0000003 discounted reward 19.2530193\n",
      "Episode 131 return 1974.0000003 discounted reward 6.8243543\n",
      "Episode 132 return 1640.0000003 discounted reward 9.7479783\n",
      "Episode 133 return 1700.0000003 discounted reward 7.4155483\n",
      "Episode 134 return 1748.0000003 discounted reward 13.2371053\n",
      "Episode 135 return 1718.0000003 discounted reward 13.5656493\n",
      "Episode 136 return 1524.0000003 discounted reward 17.3249883\n",
      "Episode 137 return 1740.0000003 discounted reward 17.2679523\n",
      "Episode 138 return 1776.0000003 discounted reward 9.4032713\n",
      "Episode 139 return 1704.0000003 discounted reward 21.6841853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 140 return 1560.0000003 discounted reward 10.5432873\n",
      "Episode 141 return 1766.0000003 discounted reward 13.4748173\n",
      "Episode 142 return 1696.0000003 discounted reward 13.2116083\n",
      "Episode 143 return 1900.0000003 discounted reward 11.1766743\n",
      "Episode 144 return 1924.0000003 discounted reward 18.3996743\n",
      "Episode 145 return 2428.0000003 discounted reward 12.1405463\n",
      "Episode 146 return 1770.0000003 discounted reward 14.7411293\n",
      "Episode 147 return 1736.0000003 discounted reward 26.0159713\n",
      "Episode 148 return 1874.0000003 discounted reward 23.1774323\n",
      "Episode 149 return 1934.0000003 discounted reward 7.5619203\n",
      "Episode 150 return 1702.0000003 discounted reward 18.6313813\n",
      "Episode 151 return 1964.0000003 discounted reward 13.6064183\n",
      "Episode 152 return 2140.0000003 discounted reward 8.3448013\n",
      "Episode 153 return 1658.0000003 discounted reward 8.3508973\n",
      "Episode 154 return 2024.0000003 discounted reward 25.6271733\n",
      "Episode 155 return 2060.0000003 discounted reward 9.7501463\n",
      "Episode 156 return 2152.0000003 discounted reward 13.5304273\n",
      "Episode 157 return 1642.0000003 discounted reward 15.7601243\n",
      "Episode 158 return 1876.0000003 discounted reward 13.6048043\n",
      "Episode 159 return 1946.0000003 discounted reward 11.7926883\n",
      "Episode 160 return 1928.0000003 discounted reward 18.3182333\n",
      "Episode 161 return 1692.0000003 discounted reward 14.4757733\n",
      "Episode 162 return 1788.0000003 discounted reward 17.6742053\n",
      "Episode 163 return 1948.0000003 discounted reward 16.3728903\n",
      "Episode 164 return 1906.0000003 discounted reward 8.9728573\n",
      "Episode 165 return 1884.0000003 discounted reward 9.7545353\n",
      "Episode 166 return 1988.0000003 discounted reward 9.5902683\n",
      "Episode 167 return 1816.0000003 discounted reward 7.1234153\n",
      "Episode 168 return 1964.0000003 discounted reward 18.3791093\n",
      "Episode 169 return 1602.0000003 discounted reward 9.0570443\n",
      "Episode 170 return 1970.0000003 discounted reward 17.6854983\n",
      "Episode 171 return 2146.0000003 discounted reward 8.5222583\n",
      "Episode 172 return 1818.0000003 discounted reward 11.8368153\n",
      "Episode 173 return 1856.0000003 discounted reward 15.1861933\n",
      "Episode 174 return 1788.0000003 discounted reward 11.9041043\n",
      "Episode 175 return 1744.0000003 discounted reward 19.1250543\n",
      "Episode 176 return 1786.0000003 discounted reward 12.8715783\n",
      "Episode 177 return 1742.0000003 discounted reward 15.4475543\n",
      "Episode 178 return 1640.0000003 discounted reward 9.3848503\n",
      "Episode 179 return 1660.0000003 discounted reward 28.8910873\n",
      "Episode 180 return 1814.0000003 discounted reward 9.1700523\n",
      "Episode 181 return 1774.0000003 discounted reward 21.2889323\n",
      "Episode 182 return 1796.0000003 discounted reward 20.3832653\n",
      "Episode 183 return 1538.0000003 discounted reward 9.9387223\n",
      "Episode 184 return 1776.0000003 discounted reward 7.9855353\n",
      "Episode 185 return 2002.0000003 discounted reward 16.0681943\n",
      "Episode 186 return 1896.0000003 discounted reward 10.7528053\n",
      "Episode 187 return 1908.0000003 discounted reward 10.2093103\n",
      "Episode 188 return 2008.0000003 discounted reward 8.5024383\n",
      "Episode 189 return 1858.0000003 discounted reward 12.1885613\n",
      "Episode 190 return 1936.0000003 discounted reward 25.3165353\n",
      "Episode 191 return 1610.0000003 discounted reward 9.5739443\n",
      "Episode 192 return 1892.0000003 discounted reward 12.4086443\n",
      "Episode 193 return 2214.0000003 discounted reward 14.6251743\n",
      "Episode 194 return 2060.0000003 discounted reward 14.6271823\n",
      "Episode 195 return 1862.0000003 discounted reward 11.9186373\n",
      "Episode 196 return 2138.0000003 discounted reward 12.0844993\n",
      "Episode 197 return 1996.0000003 discounted reward 37.2910013\n",
      "Episode 198 return 1604.0000003 discounted reward 8.8038623\n",
      "Episode 199 return 2088.0000003 discounted reward 17.4435423\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"NChain-v0\")\n",
    "num_actions = 2\n",
    "\n",
    "file_name = \"log_files/NChain-q-learning-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "\n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 1000):\n",
    "    Q = defaultdict(lambda: np.zeros(num_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, num_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "            \n",
    "        # human modifies Q\n",
    "        Q[0][0] += 0.1\n",
    "        Q[1][0] += 0.1\n",
    "        Q[2][0] += 0.1\n",
    "        Q[3][0] += 0.1\n",
    "        Q[4][0] += 0.1\n",
    "        \n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
