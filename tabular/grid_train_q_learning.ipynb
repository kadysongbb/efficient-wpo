{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import time\n",
    "import csv\n",
    "import gym_gridworld\n",
    "import itertools\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move to Yellow Room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 1 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 2 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 3 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 4 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 5 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 6 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 7 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 8 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 9 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 10 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 11 return 70.0000003 discounted reward -5.3369733\n",
      "Episode 12 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 13 return 78.0000003 discounted reward 0.8324803\n",
      "Episode 14 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 15 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 16 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 17 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 18 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 19 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 20 return 51.0000003 discounted reward -9.3700943\n",
      "Episode 21 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 22 return 75.0000003 discounted reward -2.1031223\n",
      "Episode 23 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 24 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 25 return 53.0000003 discounted reward -9.2223383\n",
      "Episode 26 return 70.0000003 discounted reward -5.3369733\n",
      "Episode 27 return 70.0000003 discounted reward -5.3369733\n",
      "Episode 28 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 29 return 69.0000003 discounted reward -5.8032753\n",
      "Episode 30 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 31 return 71.0000003 discounted reward -4.8188583\n",
      "Episode 32 return 58.0000003 discounted reward -8.6830233\n",
      "Episode 33 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 34 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 35 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 36 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 37 return 72.0000003 discounted reward -4.2431763\n",
      "Episode 38 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 39 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 40 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 41 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 42 return 73.0000003 discounted reward -3.6035293\n",
      "Episode 43 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 44 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 45 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 46 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 47 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 48 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 49 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 50 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 51 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 52 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 53 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 54 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 55 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 56 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 57 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 58 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 59 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 60 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 61 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 62 return 70.0000003 discounted reward -5.3369733\n",
      "Episode 63 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 64 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 65 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 66 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 67 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 68 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 69 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 70 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 71 return 78.0000003 discounted reward 0.8324803\n",
      "Episode 72 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 73 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 74 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 75 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 76 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 77 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 78 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 79 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 80 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 81 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 82 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 83 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 84 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 85 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 86 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 87 return 76.0000003 discounted reward -1.2256913\n",
      "Episode 88 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 89 return 71.0000003 discounted reward -4.8188583\n",
      "Episode 90 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 91 return 54.0000003 discounted reward -9.1359323\n",
      "Episode 92 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 93 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 94 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 95 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 96 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 97 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 98 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 99 return 93.0000003 discounted reward 42.6126593\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"GridWorld-v0\")\n",
    "file_name = \"log_files/GridWorld-q-learning/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "\n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 50):\n",
    "    Q = defaultdict(lambda: np.zeros(env.n_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.n_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human in the Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 1 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 2 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 3 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 4 return 74.0000003 discounted reward -2.8928103\n",
      "Episode 5 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 6 return 78.0000003 discounted reward 0.8324803\n",
      "Episode 7 return 77.0000003 discounted reward -0.2507683\n",
      "Episode 8 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 9 return 65.0000003 discounted reward -7.2465293\n",
      "Episode 10 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 11 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 12 return 64.0000003 discounted reward -7.5218763\n",
      "Episode 13 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 14 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 15 return 74.0000003 discounted reward -2.8928103\n",
      "Episode 16 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 17 return 77.0000003 discounted reward -0.2507683\n",
      "Episode 18 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 19 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 20 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 21 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 22 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 23 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 24 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 25 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 26 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 27 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 28 return 66.0000003 discounted reward -6.9405883\n",
      "Episode 29 return 57.0000003 discounted reward -8.8147213\n",
      "Episode 30 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 31 return 73.0000003 discounted reward -3.6035293\n",
      "Episode 32 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 33 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 34 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 35 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 36 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 37 return 80.0000003 discounted reward 3.3734323\n",
      "Episode 38 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 39 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 40 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 41 return 78.0000003 discounted reward 0.8324803\n",
      "Episode 42 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 43 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 44 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 45 return 67.0000003 discounted reward -6.6006533\n",
      "Episode 46 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 47 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 48 return 61.0000003 discounted reward -8.1934483\n",
      "Episode 49 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 50 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 51 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 52 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 53 return 72.0000003 discounted reward -4.2431763\n",
      "Episode 54 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 55 return 73.0000003 discounted reward -3.6035293\n",
      "Episode 56 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 57 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 58 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 59 return 65.0000003 discounted reward -7.2465293\n",
      "Episode 60 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 61 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 62 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 63 return 61.0000003 discounted reward -8.1934483\n",
      "Episode 64 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 65 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 66 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 67 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 68 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 69 return 80.0000003 discounted reward 3.3734323\n",
      "Episode 70 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 71 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 72 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 73 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 74 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 75 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 76 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 77 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 78 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 79 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 80 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 81 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 82 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 83 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 84 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 85 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 86 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 87 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 88 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 89 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 90 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 91 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 92 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 93 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 94 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 95 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 96 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 97 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 98 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 99 return 81.0000003 discounted reward 4.8593693\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"GridWorld-v0\")\n",
    "file_name = \"log_files/GridWorld-q-learning-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "    \n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 50):\n",
    "    Q = defaultdict(lambda: np.zeros(env.n_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.n_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "        # human modifies the Q\n",
    "        # left red room\n",
    "        Q[0][2] += 1\n",
    "        Q[8][2] += 1\n",
    "        Q[16][2] += 1\n",
    "        Q[24][1] += 1\n",
    "        Q[32][0] += 1\n",
    "        Q[40][0] += 1\n",
    "        Q[48][0] += 1\n",
    "        \n",
    "        Q[1][2] += 1\n",
    "        Q[9][2] += 1\n",
    "        Q[17][2] += 1\n",
    "        Q[25][1] += 1\n",
    "        Q[33][0] += 1\n",
    "        Q[41][0] += 1\n",
    "        Q[49][0] += 1\n",
    "        \n",
    "        \n",
    "        # middle path \n",
    "        Q[26][1] += 1\n",
    "        \n",
    "        # middle blue room\n",
    "        Q[3][2] += 1\n",
    "        Q[11][2] += 1\n",
    "        Q[19][2] += 1\n",
    "        Q[27][1] += 1\n",
    "        Q[35][0] += 1\n",
    "        Q[43][0] += 1\n",
    "        Q[51][0] += 1\n",
    "        \n",
    "        Q[4][2] += 1\n",
    "        Q[12][2] += 1\n",
    "        Q[20][2] += 1\n",
    "        Q[28][1] += 1\n",
    "        Q[36][0] += 1\n",
    "        Q[44][0] += 1\n",
    "        Q[52][0] += 1\n",
    "        \n",
    "        # middle path \n",
    "        Q[29][1] += 1\n",
    "        \n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return 1618.0000003 discounted reward 20.6467793\n",
      "Episode 1 return 1664.0000003 discounted reward 13.4598533\n",
      "Episode 2 return 1822.0000003 discounted reward 18.7914663\n",
      "Episode 3 return 1760.0000003 discounted reward 15.8270593\n",
      "Episode 4 return 1444.0000003 discounted reward 9.6674923\n",
      "Episode 5 return 1866.0000003 discounted reward 15.5843763\n",
      "Episode 6 return 1874.0000003 discounted reward 16.3389123\n",
      "Episode 7 return 1994.0000003 discounted reward 9.5106893\n",
      "Episode 8 return 1784.0000003 discounted reward 8.1861563\n",
      "Episode 9 return 1986.0000003 discounted reward 11.4517933\n",
      "Episode 10 return 1736.0000003 discounted reward 7.0121343\n",
      "Episode 11 return 1786.0000003 discounted reward 10.8719253\n",
      "Episode 12 return 1712.0000003 discounted reward 20.0499353\n",
      "Episode 13 return 1700.0000003 discounted reward 21.8366203\n",
      "Episode 14 return 2078.0000003 discounted reward 14.0458063\n",
      "Episode 15 return 1734.0000003 discounted reward 17.3067913\n",
      "Episode 16 return 1882.0000003 discounted reward 9.6786243\n",
      "Episode 17 return 1790.0000003 discounted reward 7.5574983\n",
      "Episode 18 return 1726.0000003 discounted reward 13.5108033\n",
      "Episode 19 return 1968.0000003 discounted reward 34.2943143\n",
      "Episode 20 return 1812.0000003 discounted reward 7.5350843\n",
      "Episode 21 return 2014.0000003 discounted reward 12.0207553\n",
      "Episode 22 return 2042.0000003 discounted reward 27.7671763\n",
      "Episode 23 return 1790.0000003 discounted reward 12.2715363\n",
      "Episode 24 return 1932.0000003 discounted reward 9.3962953\n",
      "Episode 25 return 1754.0000003 discounted reward 14.7919813\n",
      "Episode 26 return 1906.0000003 discounted reward 19.6160983\n",
      "Episode 27 return 1972.0000003 discounted reward 15.1043623\n",
      "Episode 28 return 1806.0000003 discounted reward 25.8139683\n",
      "Episode 29 return 1852.0000003 discounted reward 7.4159683\n",
      "Episode 30 return 1854.0000003 discounted reward 12.9342143\n",
      "Episode 31 return 1784.0000003 discounted reward 12.2540553\n",
      "Episode 32 return 2026.0000003 discounted reward 13.5960873\n",
      "Episode 33 return 1684.0000003 discounted reward 10.8738103\n",
      "Episode 34 return 1630.0000003 discounted reward 11.6584933\n",
      "Episode 35 return 1892.0000003 discounted reward 10.4046273\n",
      "Episode 36 return 2064.0000003 discounted reward 12.4763563\n",
      "Episode 37 return 2004.0000003 discounted reward 27.4196713\n",
      "Episode 38 return 2092.0000003 discounted reward 13.0265173\n",
      "Episode 39 return 1754.0000003 discounted reward 17.3831853\n",
      "Episode 40 return 1732.0000003 discounted reward 15.8832223\n",
      "Episode 41 return 1654.0000003 discounted reward 15.0001863\n",
      "Episode 42 return 1934.0000003 discounted reward 15.7492593\n",
      "Episode 43 return 2136.0000003 discounted reward 7.4155273\n",
      "Episode 44 return 1758.0000003 discounted reward 6.2054463\n",
      "Episode 45 return 1908.0000003 discounted reward 10.4114243\n",
      "Episode 46 return 1954.0000003 discounted reward 12.7848293\n",
      "Episode 47 return 1696.0000003 discounted reward 26.8864983\n",
      "Episode 48 return 2080.0000003 discounted reward 14.1622733\n",
      "Episode 49 return 1852.0000003 discounted reward 25.0359683\n",
      "Episode 50 return 1824.0000003 discounted reward 10.4012043\n",
      "Episode 51 return 1836.0000003 discounted reward 21.5383523\n",
      "Episode 52 return 1992.0000003 discounted reward 11.0447383\n",
      "Episode 53 return 1968.0000003 discounted reward 21.9996943\n",
      "Episode 54 return 1868.0000003 discounted reward 14.8040143\n",
      "Episode 55 return 1720.0000003 discounted reward 16.0814793\n",
      "Episode 56 return 1894.0000003 discounted reward 15.1075603\n",
      "Episode 57 return 1756.0000003 discounted reward 6.6863403\n",
      "Episode 58 return 2060.0000003 discounted reward 13.6021093\n",
      "Episode 59 return 1702.0000003 discounted reward 8.4509473\n",
      "Episode 60 return 1906.0000003 discounted reward 8.7978103\n",
      "Episode 61 return 1680.0000003 discounted reward 19.0238443\n",
      "Episode 62 return 2114.0000003 discounted reward 22.1716883\n",
      "Episode 63 return 1970.0000003 discounted reward 11.3573383\n",
      "Episode 64 return 1886.0000003 discounted reward 17.5604893\n",
      "Episode 65 return 1802.0000003 discounted reward 5.9479283\n",
      "Episode 66 return 1752.0000003 discounted reward 8.9568723\n",
      "Episode 67 return 1782.0000003 discounted reward 8.0434683\n",
      "Episode 68 return 1778.0000003 discounted reward 12.7754213\n",
      "Episode 69 return 1826.0000003 discounted reward 6.5443993\n",
      "Episode 70 return 1850.0000003 discounted reward 24.2556843\n",
      "Episode 71 return 1920.0000003 discounted reward 9.4379863\n",
      "Episode 72 return 1896.0000003 discounted reward 11.7347103\n",
      "Episode 73 return 2002.0000003 discounted reward 7.4565423\n",
      "Episode 74 return 1850.0000003 discounted reward 9.5737873\n",
      "Episode 75 return 1736.0000003 discounted reward 15.3367453\n",
      "Episode 76 return 2000.0000003 discounted reward 41.6819603\n",
      "Episode 77 return 1808.0000003 discounted reward 31.0291173\n",
      "Episode 78 return 1888.0000003 discounted reward 15.7155873\n",
      "Episode 79 return 1612.0000003 discounted reward 7.2158523\n",
      "Episode 80 return 1922.0000003 discounted reward 12.6877373\n",
      "Episode 81 return 2110.0000003 discounted reward 18.9689883\n",
      "Episode 82 return 2174.0000003 discounted reward 7.5608433\n",
      "Episode 83 return 1948.0000003 discounted reward 9.7750543\n",
      "Episode 84 return 2030.0000003 discounted reward 12.8778653\n",
      "Episode 85 return 2000.0000003 discounted reward 22.9181513\n",
      "Episode 86 return 1996.0000003 discounted reward 11.9461993\n",
      "Episode 87 return 1964.0000003 discounted reward 14.6749863\n",
      "Episode 88 return 2024.0000003 discounted reward 11.8725693\n",
      "Episode 89 return 1876.0000003 discounted reward 10.9630573\n",
      "Episode 90 return 1892.0000003 discounted reward 12.0592983\n",
      "Episode 91 return 1828.0000003 discounted reward 11.4340953\n",
      "Episode 92 return 1896.0000003 discounted reward 26.2382733\n",
      "Episode 93 return 1740.0000003 discounted reward 8.9641023\n",
      "Episode 94 return 2094.0000003 discounted reward 21.5090183\n",
      "Episode 95 return 2208.0000003 discounted reward 17.6707923\n",
      "Episode 96 return 1720.0000003 discounted reward 16.6814883\n",
      "Episode 97 return 1794.0000003 discounted reward 7.3866113\n",
      "Episode 98 return 1656.0000003 discounted reward 10.4637383\n",
      "Episode 99 return 1886.0000003 discounted reward 12.7751673\n",
      "Episode 100 return 1736.0000003 discounted reward 13.1681643\n",
      "Episode 101 return 1962.0000003 discounted reward 13.3643243\n",
      "Episode 102 return 1810.0000003 discounted reward 12.8148823\n",
      "Episode 103 return 1864.0000003 discounted reward 24.8039683\n",
      "Episode 104 return 1856.0000003 discounted reward 11.0458193\n",
      "Episode 105 return 1770.0000003 discounted reward 11.6786943\n",
      "Episode 106 return 1708.0000003 discounted reward 22.5049203\n",
      "Episode 107 return 1986.0000003 discounted reward 12.9522783\n",
      "Episode 108 return 2122.0000003 discounted reward 12.4576443\n",
      "Episode 109 return 1890.0000003 discounted reward 23.9505463\n",
      "Episode 110 return 1714.0000003 discounted reward 16.9282623\n",
      "Episode 111 return 1722.0000003 discounted reward 11.8914563\n",
      "Episode 112 return 1658.0000003 discounted reward 12.4390713\n",
      "Episode 113 return 1938.0000003 discounted reward 12.0687373\n",
      "Episode 114 return 2286.0000003 discounted reward 39.2010153\n",
      "Episode 115 return 1484.0000003 discounted reward 10.3206033\n",
      "Episode 116 return 1878.0000003 discounted reward 11.9476243\n",
      "Episode 117 return 1896.0000003 discounted reward 23.4660843\n",
      "Episode 118 return 1580.0000003 discounted reward 10.9623143\n",
      "Episode 119 return 1798.0000003 discounted reward 17.4107893\n",
      "Episode 120 return 1660.0000003 discounted reward 9.7938213\n",
      "Episode 121 return 2168.0000003 discounted reward 26.1118973\n",
      "Episode 122 return 1684.0000003 discounted reward 7.0034683\n",
      "Episode 123 return 1672.0000003 discounted reward 8.5730943\n",
      "Episode 124 return 1794.0000003 discounted reward 10.2735803\n",
      "Episode 125 return 1802.0000003 discounted reward 18.7545983\n",
      "Episode 126 return 1852.0000003 discounted reward 11.9049123\n",
      "Episode 127 return 1754.0000003 discounted reward 8.4185953\n",
      "Episode 128 return 1964.0000003 discounted reward 15.7544133\n",
      "Episode 129 return 2124.0000003 discounted reward 10.7985113\n",
      "Episode 130 return 1844.0000003 discounted reward 13.0626253\n",
      "Episode 131 return 1738.0000003 discounted reward 24.5827673\n",
      "Episode 132 return 1578.0000003 discounted reward 16.4115833\n",
      "Episode 133 return 1788.0000003 discounted reward 23.5735883\n",
      "Episode 134 return 1804.0000003 discounted reward 15.2194243\n",
      "Episode 135 return 1830.0000003 discounted reward 12.3639273\n",
      "Episode 136 return 1782.0000003 discounted reward 8.8466253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 137 return 1890.0000003 discounted reward 9.7885633\n",
      "Episode 138 return 1512.0000003 discounted reward 10.0272743\n",
      "Episode 139 return 1706.0000003 discounted reward 15.5729323\n",
      "Episode 140 return 1650.0000003 discounted reward 15.6557613\n",
      "Episode 141 return 1776.0000003 discounted reward 12.2141543\n",
      "Episode 142 return 2040.0000003 discounted reward 10.6549063\n",
      "Episode 143 return 1810.0000003 discounted reward 30.6608883\n",
      "Episode 144 return 1760.0000003 discounted reward 17.8287453\n",
      "Episode 145 return 2080.0000003 discounted reward 26.1084833\n",
      "Episode 146 return 2246.0000003 discounted reward 25.3702673\n",
      "Episode 147 return 1936.0000003 discounted reward 12.5211453\n",
      "Episode 148 return 2070.0000003 discounted reward 9.3269203\n",
      "Episode 149 return 1670.0000003 discounted reward 13.6379373\n",
      "Episode 150 return 1678.0000003 discounted reward 12.0659153\n",
      "Episode 151 return 1796.0000003 discounted reward 22.2539763\n",
      "Episode 152 return 2014.0000003 discounted reward 16.2122733\n",
      "Episode 153 return 1978.0000003 discounted reward 11.4047583\n",
      "Episode 154 return 1854.0000003 discounted reward 10.3583003\n",
      "Episode 155 return 1770.0000003 discounted reward 9.4685633\n",
      "Episode 156 return 1592.0000003 discounted reward 12.8510693\n",
      "Episode 157 return 1934.0000003 discounted reward 19.7414353\n",
      "Episode 158 return 1780.0000003 discounted reward 13.8068323\n",
      "Episode 159 return 1584.0000003 discounted reward 7.3421733\n",
      "Episode 160 return 1796.0000003 discounted reward 15.9235313\n",
      "Episode 161 return 1810.0000003 discounted reward 10.9944243\n",
      "Episode 162 return 1986.0000003 discounted reward 9.6667693\n",
      "Episode 163 return 1704.0000003 discounted reward 11.7223553\n",
      "Episode 164 return 1920.0000003 discounted reward 25.6685923\n",
      "Episode 165 return 1952.0000003 discounted reward 14.3896913\n",
      "Episode 166 return 1968.0000003 discounted reward 12.5168543\n",
      "Episode 167 return 1750.0000003 discounted reward 11.8650243\n",
      "Episode 168 return 1970.0000003 discounted reward 11.3790563\n",
      "Episode 169 return 1784.0000003 discounted reward 14.5846113\n",
      "Episode 170 return 2150.0000003 discounted reward 17.5002153\n",
      "Episode 171 return 1788.0000003 discounted reward 18.3224283\n",
      "Episode 172 return 1632.0000003 discounted reward 11.6284943\n",
      "Episode 173 return 1750.0000003 discounted reward 17.7749153\n",
      "Episode 174 return 2072.0000003 discounted reward 11.2553363\n",
      "Episode 175 return 1882.0000003 discounted reward 9.8540093\n",
      "Episode 176 return 1642.0000003 discounted reward 13.9003203\n",
      "Episode 177 return 1974.0000003 discounted reward 14.1709203\n",
      "Episode 178 return 1820.0000003 discounted reward 13.7932643\n",
      "Episode 179 return 1866.0000003 discounted reward 18.1106973\n",
      "Episode 180 return 1976.0000003 discounted reward 13.6624573\n",
      "Episode 181 return 1642.0000003 discounted reward 13.4012773\n",
      "Episode 182 return 1876.0000003 discounted reward 13.0599313\n",
      "Episode 183 return 2090.0000003 discounted reward 6.0853283\n",
      "Episode 184 return 1770.0000003 discounted reward 8.7152143\n",
      "Episode 185 return 2154.0000003 discounted reward 8.3037863\n",
      "Episode 186 return 1908.0000003 discounted reward 12.8966983\n",
      "Episode 187 return 1852.0000003 discounted reward 9.9977963\n",
      "Episode 188 return 1796.0000003 discounted reward 17.9363113\n",
      "Episode 189 return 1668.0000003 discounted reward 10.7849673\n",
      "Episode 190 return 1840.0000003 discounted reward 20.0926623\n",
      "Episode 191 return 1892.0000003 discounted reward 12.0391443\n",
      "Episode 192 return 1594.0000003 discounted reward 16.2660663\n",
      "Episode 193 return 1486.0000003 discounted reward 20.3369753\n",
      "Episode 194 return 1696.0000003 discounted reward 11.7432393\n",
      "Episode 195 return 2008.0000003 discounted reward 11.5512343\n",
      "Episode 196 return 1840.0000003 discounted reward 12.8405483\n",
      "Episode 197 return 2026.0000003 discounted reward 9.3808523\n",
      "Episode 198 return 2140.0000003 discounted reward 33.4205173\n",
      "Episode 199 return 1780.0000003 discounted reward 27.6144173\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"NChain-v0\")\n",
    "num_actions = 2\n",
    "\n",
    "file_name = \"log_files/NChain-q-learning/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "\n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 1000):\n",
    "    Q = defaultdict(lambda: np.zeros(num_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, num_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human in the Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return 1440.0000003 discounted reward 11.4550733\n",
      "Episode 1 return 1622.0000003 discounted reward 14.2389633\n",
      "Episode 2 return 1802.0000003 discounted reward 35.0993303\n",
      "Episode 3 return 2168.0000003 discounted reward 18.7066983\n",
      "Episode 4 return 1666.0000003 discounted reward 11.8945273\n",
      "Episode 5 return 1870.0000003 discounted reward 23.1421353\n",
      "Episode 6 return 1780.0000003 discounted reward 22.3740233\n",
      "Episode 7 return 1868.0000003 discounted reward 22.6883463\n",
      "Episode 8 return 1870.0000003 discounted reward 15.8247103\n",
      "Episode 9 return 1974.0000003 discounted reward 11.4946593\n",
      "Episode 10 return 1760.0000003 discounted reward 15.2294253\n",
      "Episode 11 return 1812.0000003 discounted reward 10.8617993\n",
      "Episode 12 return 1758.0000003 discounted reward 11.0056623\n",
      "Episode 13 return 1796.0000003 discounted reward 13.5323953\n",
      "Episode 14 return 1756.0000003 discounted reward 10.1697363\n",
      "Episode 15 return 1810.0000003 discounted reward 8.9477813\n",
      "Episode 16 return 1794.0000003 discounted reward 20.2861393\n",
      "Episode 17 return 1806.0000003 discounted reward 12.9770343\n",
      "Episode 18 return 2018.0000003 discounted reward 16.5346263\n",
      "Episode 19 return 1820.0000003 discounted reward 7.6403683\n",
      "Episode 20 return 1860.0000003 discounted reward 10.2575183\n",
      "Episode 21 return 1778.0000003 discounted reward 14.1302373\n",
      "Episode 22 return 1972.0000003 discounted reward 9.0559583\n",
      "Episode 23 return 1736.0000003 discounted reward 12.4802803\n",
      "Episode 24 return 1864.0000003 discounted reward 22.0804813\n",
      "Episode 25 return 1656.0000003 discounted reward 6.7576583\n",
      "Episode 26 return 1990.0000003 discounted reward 29.1948473\n",
      "Episode 27 return 2272.0000003 discounted reward 20.0566463\n",
      "Episode 28 return 1758.0000003 discounted reward 22.1018463\n",
      "Episode 29 return 1934.0000003 discounted reward 19.8835943\n",
      "Episode 30 return 1902.0000003 discounted reward 14.9595893\n",
      "Episode 31 return 1902.0000003 discounted reward 7.6477163\n",
      "Episode 32 return 1638.0000003 discounted reward 7.7719363\n",
      "Episode 33 return 1744.0000003 discounted reward 11.4757483\n",
      "Episode 34 return 1928.0000003 discounted reward 15.3598653\n",
      "Episode 35 return 1782.0000003 discounted reward 41.0248283\n",
      "Episode 36 return 2022.0000003 discounted reward 29.3963993\n",
      "Episode 37 return 1734.0000003 discounted reward 21.2356383\n",
      "Episode 38 return 1890.0000003 discounted reward 11.9738713\n",
      "Episode 39 return 1798.0000003 discounted reward 15.5641883\n",
      "Episode 40 return 2030.0000003 discounted reward 11.1267223\n",
      "Episode 41 return 1546.0000003 discounted reward 13.4591313\n",
      "Episode 42 return 1874.0000003 discounted reward 10.1004453\n",
      "Episode 43 return 1876.0000003 discounted reward 7.5791863\n",
      "Episode 44 return 1968.0000003 discounted reward 14.9961413\n",
      "Episode 45 return 1646.0000003 discounted reward 13.5824563\n",
      "Episode 46 return 1892.0000003 discounted reward 17.7308663\n",
      "Episode 47 return 2118.0000003 discounted reward 7.8787413\n",
      "Episode 48 return 1780.0000003 discounted reward 19.8804973\n",
      "Episode 49 return 1714.0000003 discounted reward 8.8468863\n",
      "Episode 50 return 1948.0000003 discounted reward 18.2218283\n",
      "Episode 51 return 1842.0000003 discounted reward 18.8785203\n",
      "Episode 52 return 1896.0000003 discounted reward 13.0601793\n",
      "Episode 53 return 1790.0000003 discounted reward 36.8014783\n",
      "Episode 54 return 1824.0000003 discounted reward 17.8920833\n",
      "Episode 55 return 1974.0000003 discounted reward 7.9372153\n",
      "Episode 56 return 2304.0000003 discounted reward 13.5946093\n",
      "Episode 57 return 1588.0000003 discounted reward 22.6090873\n",
      "Episode 58 return 1920.0000003 discounted reward 25.1373563\n",
      "Episode 59 return 1952.0000003 discounted reward 13.6509043\n",
      "Episode 60 return 1962.0000003 discounted reward 9.9406363\n",
      "Episode 61 return 1420.0000003 discounted reward 8.2401743\n",
      "Episode 62 return 1762.0000003 discounted reward 12.6558933\n",
      "Episode 63 return 1724.0000003 discounted reward 11.0539913\n",
      "Episode 64 return 1654.0000003 discounted reward 6.4245383\n",
      "Episode 65 return 1706.0000003 discounted reward 23.1511503\n",
      "Episode 66 return 1848.0000003 discounted reward 13.7151453\n",
      "Episode 67 return 2002.0000003 discounted reward 11.6054813\n",
      "Episode 68 return 1878.0000003 discounted reward 12.9589673\n",
      "Episode 69 return 1696.0000003 discounted reward 13.0889173\n",
      "Episode 70 return 2040.0000003 discounted reward 14.7841333\n",
      "Episode 71 return 1850.0000003 discounted reward 16.7743363\n",
      "Episode 72 return 2162.0000003 discounted reward 11.9703923\n",
      "Episode 73 return 2000.0000003 discounted reward 8.2181813\n",
      "Episode 74 return 2154.0000003 discounted reward 18.7661433\n",
      "Episode 75 return 1816.0000003 discounted reward 21.9804953\n",
      "Episode 76 return 1792.0000003 discounted reward 10.7610403\n",
      "Episode 77 return 1846.0000003 discounted reward 10.4540643\n",
      "Episode 78 return 1832.0000003 discounted reward 6.8861893\n",
      "Episode 79 return 1942.0000003 discounted reward 9.6105533\n",
      "Episode 80 return 1596.0000003 discounted reward 10.4516213\n",
      "Episode 81 return 1954.0000003 discounted reward 17.2118403\n",
      "Episode 82 return 1920.0000003 discounted reward 29.7008603\n",
      "Episode 83 return 2010.0000003 discounted reward 10.6255943\n",
      "Episode 84 return 1920.0000003 discounted reward 15.0014733\n",
      "Episode 85 return 1962.0000003 discounted reward 22.8826203\n",
      "Episode 86 return 2016.0000003 discounted reward 21.0451683\n",
      "Episode 87 return 1928.0000003 discounted reward 8.7567913\n",
      "Episode 88 return 1860.0000003 discounted reward 6.9468473\n",
      "Episode 89 return 1906.0000003 discounted reward 11.8846823\n",
      "Episode 90 return 1638.0000003 discounted reward 7.7369093\n",
      "Episode 91 return 1826.0000003 discounted reward 17.9517013\n",
      "Episode 92 return 1760.0000003 discounted reward 13.7124593\n",
      "Episode 93 return 1900.0000003 discounted reward 11.0045463\n",
      "Episode 94 return 1836.0000003 discounted reward 21.0942593\n",
      "Episode 95 return 2026.0000003 discounted reward 8.2592433\n",
      "Episode 96 return 1826.0000003 discounted reward 10.4964843\n",
      "Episode 97 return 1776.0000003 discounted reward 11.3807523\n",
      "Episode 98 return 1706.0000003 discounted reward 20.1151063\n",
      "Episode 99 return 1672.0000003 discounted reward 30.8425013\n",
      "Episode 100 return 1730.0000003 discounted reward 28.5081443\n",
      "Episode 101 return 1700.0000003 discounted reward 16.9308573\n",
      "Episode 102 return 1778.0000003 discounted reward 31.4827173\n",
      "Episode 103 return 2052.0000003 discounted reward 10.6484483\n",
      "Episode 104 return 2024.0000003 discounted reward 8.6608763\n",
      "Episode 105 return 1872.0000003 discounted reward 10.6263883\n",
      "Episode 106 return 1782.0000003 discounted reward 10.7375703\n",
      "Episode 107 return 1856.0000003 discounted reward 12.0873753\n",
      "Episode 108 return 1880.0000003 discounted reward 20.8066783\n",
      "Episode 109 return 1890.0000003 discounted reward 6.4281053\n",
      "Episode 110 return 1874.0000003 discounted reward 10.7687433\n",
      "Episode 111 return 1834.0000003 discounted reward 12.4090693\n",
      "Episode 112 return 1936.0000003 discounted reward 21.2931833\n",
      "Episode 113 return 1884.0000003 discounted reward 16.1272263\n",
      "Episode 114 return 1986.0000003 discounted reward 7.1456453\n",
      "Episode 115 return 1964.0000003 discounted reward 13.5859643\n",
      "Episode 116 return 2050.0000003 discounted reward 29.0998433\n",
      "Episode 117 return 2092.0000003 discounted reward 8.6729213\n",
      "Episode 118 return 1446.0000003 discounted reward 8.4316123\n",
      "Episode 119 return 1580.0000003 discounted reward 10.7716913\n",
      "Episode 120 return 1884.0000003 discounted reward 17.3874553\n",
      "Episode 121 return 1998.0000003 discounted reward 12.6493613\n",
      "Episode 122 return 1700.0000003 discounted reward 10.7587493\n",
      "Episode 123 return 1834.0000003 discounted reward 12.0176403\n",
      "Episode 124 return 1664.0000003 discounted reward 10.9428713\n",
      "Episode 125 return 1742.0000003 discounted reward 11.2491383\n",
      "Episode 126 return 1814.0000003 discounted reward 6.3828643\n",
      "Episode 127 return 2042.0000003 discounted reward 12.2568963\n",
      "Episode 128 return 1932.0000003 discounted reward 12.5997063\n",
      "Episode 129 return 1920.0000003 discounted reward 12.8856493\n",
      "Episode 130 return 1872.0000003 discounted reward 10.8896053\n",
      "Episode 131 return 1668.0000003 discounted reward 37.0556003\n",
      "Episode 132 return 1728.0000003 discounted reward 8.9712583\n",
      "Episode 133 return 2060.0000003 discounted reward 5.6644813\n",
      "Episode 134 return 2038.0000003 discounted reward 11.3413653\n",
      "Episode 135 return 1880.0000003 discounted reward 12.1374213\n",
      "Episode 136 return 1910.0000003 discounted reward 6.3116433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 137 return 2026.0000003 discounted reward 10.7710573\n",
      "Episode 138 return 1712.0000003 discounted reward 15.5175963\n",
      "Episode 139 return 1820.0000003 discounted reward 11.4959383\n",
      "Episode 140 return 1666.0000003 discounted reward 17.6749923\n",
      "Episode 141 return 2002.0000003 discounted reward 16.4980063\n",
      "Episode 142 return 1768.0000003 discounted reward 11.2939313\n",
      "Episode 143 return 1928.0000003 discounted reward 29.2109773\n",
      "Episode 144 return 1834.0000003 discounted reward 18.0576773\n",
      "Episode 145 return 1886.0000003 discounted reward 17.5897083\n",
      "Episode 146 return 2026.0000003 discounted reward 33.6529203\n",
      "Episode 147 return 1664.0000003 discounted reward 27.5632123\n",
      "Episode 148 return 1736.0000003 discounted reward 7.7182843\n",
      "Episode 149 return 2108.0000003 discounted reward 10.7945253\n",
      "Episode 150 return 1992.0000003 discounted reward 7.8252203\n",
      "Episode 151 return 1722.0000003 discounted reward 18.3134163\n",
      "Episode 152 return 1604.0000003 discounted reward 16.8708093\n",
      "Episode 153 return 1586.0000003 discounted reward 11.5601053\n",
      "Episode 154 return 2060.0000003 discounted reward 15.5489333\n",
      "Episode 155 return 1792.0000003 discounted reward 9.6745573\n",
      "Episode 156 return 1974.0000003 discounted reward 37.4109593\n",
      "Episode 157 return 1648.0000003 discounted reward 14.9184853\n",
      "Episode 158 return 2016.0000003 discounted reward 22.6319583\n",
      "Episode 159 return 1626.0000003 discounted reward 10.1574333\n",
      "Episode 160 return 1862.0000003 discounted reward 12.1413833\n",
      "Episode 161 return 1590.0000003 discounted reward 7.3577153\n",
      "Episode 162 return 1876.0000003 discounted reward 11.4957363\n",
      "Episode 163 return 1918.0000003 discounted reward 7.0239773\n",
      "Episode 164 return 1590.0000003 discounted reward 16.1698533\n",
      "Episode 165 return 1904.0000003 discounted reward 13.7323743\n",
      "Episode 166 return 1598.0000003 discounted reward 15.0519353\n",
      "Episode 167 return 1954.0000003 discounted reward 12.3469093\n",
      "Episode 168 return 1756.0000003 discounted reward 8.4772813\n",
      "Episode 169 return 1712.0000003 discounted reward 12.1713243\n",
      "Episode 170 return 1942.0000003 discounted reward 8.4797483\n",
      "Episode 171 return 2164.0000003 discounted reward 12.0258603\n",
      "Episode 172 return 1678.0000003 discounted reward 11.1445073\n",
      "Episode 173 return 1896.0000003 discounted reward 10.4470963\n",
      "Episode 174 return 1696.0000003 discounted reward 9.3432883\n",
      "Episode 175 return 2072.0000003 discounted reward 10.2704323\n",
      "Episode 176 return 1748.0000003 discounted reward 11.4695643\n",
      "Episode 177 return 1834.0000003 discounted reward 11.6875953\n",
      "Episode 178 return 1860.0000003 discounted reward 10.5247123\n",
      "Episode 179 return 1866.0000003 discounted reward 15.4135523\n",
      "Episode 180 return 1798.0000003 discounted reward 23.8711153\n",
      "Episode 181 return 1988.0000003 discounted reward 9.2300573\n",
      "Episode 182 return 1872.0000003 discounted reward 11.9326303\n",
      "Episode 183 return 2026.0000003 discounted reward 25.3013953\n",
      "Episode 184 return 1878.0000003 discounted reward 13.0275593\n",
      "Episode 185 return 1946.0000003 discounted reward 27.4274473\n",
      "Episode 186 return 1914.0000003 discounted reward 21.6861553\n",
      "Episode 187 return 1992.0000003 discounted reward 13.9949813\n",
      "Episode 188 return 1940.0000003 discounted reward 17.3845453\n",
      "Episode 189 return 2298.0000003 discounted reward 13.1882743\n",
      "Episode 190 return 1972.0000003 discounted reward 13.6574473\n",
      "Episode 191 return 1996.0000003 discounted reward 12.0174573\n",
      "Episode 192 return 1936.0000003 discounted reward 7.4991863\n",
      "Episode 193 return 1772.0000003 discounted reward 6.3314773\n",
      "Episode 194 return 2000.0000003 discounted reward 9.1240853\n",
      "Episode 195 return 1666.0000003 discounted reward 18.2918183\n",
      "Episode 196 return 2296.0000003 discounted reward 10.6687493\n",
      "Episode 197 return 1636.0000003 discounted reward 31.1288923\n",
      "Episode 198 return 1822.0000003 discounted reward 7.7308733\n",
      "Episode 199 return 1826.0000003 discounted reward 9.1793033\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"NChain-v0\")\n",
    "num_actions = 2\n",
    "\n",
    "file_name = \"log_files/NChain-q-learning-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "\n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 1000):\n",
    "    Q = defaultdict(lambda: np.zeros(num_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, num_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "            \n",
    "        # human modifies Q\n",
    "        Q[0][0] += 0.1\n",
    "        Q[1][0] += 0.1\n",
    "        Q[2][0] += 0.1\n",
    "        Q[3][0] += 0.1\n",
    "        Q[4][0] += 0.1\n",
    "        \n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
